{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 4: Noise & Edge Detection — Lab Practice\n",
    "\n",
    "**Topics:** Aliasing, Image Noise, Image Denoising, Quality Metrics (PSNR / SSIM), Edge Detection\n",
    "\n",
    "This notebook accompanies the Week 4 lecture slides. We will observe aliasing artifacts, generate and denoise different types of noise, measure image quality with PSNR and SSIM, and explore edge detection operators from Sobel to Canny — all hands-on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from scipy.ndimage import correlate, gaussian_filter, median_filter, uniform_filter\n",
    "from skimage.metrics import peak_signal_noise_ratio, structural_similarity\n",
    "from skimage.feature import canny\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Environment setup\n",
    "\n",
    "This notebook works both **locally** and on **Google Colab**.\n",
    "- **Local**: images are loaded from the repository’s `images/` folder.\n",
    "- **Colab**: images are automatically downloaded from GitHub on first run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, urllib.request\n",
    "\n",
    "# Detect Google Colab\n",
    "IN_COLAB = \"google.colab\" in str(get_ipython()) if hasattr(__builtins__, \"__IPYTHON__\") else False\n",
    "\n",
    "# Image paths\n",
    "REPO_URL = \"https://raw.githubusercontent.com/HyeongminLEE/image-processing-tutorial/main\"\n",
    "IMAGE_DIR = \"images\"\n",
    "COLOR_NAME = \"parrots_256.jpg\"\n",
    "GRAY_NAME = \"parrots_256_gray.jpg\"\n",
    "BF_FIG_NAME = \"bilateral_filter_fig6.png\"\n",
    "\n",
    "if IN_COLAB:\n",
    "    os.makedirs(IMAGE_DIR, exist_ok=True)\n",
    "    for name in [COLOR_NAME, GRAY_NAME]:\n",
    "        url = f\"{REPO_URL}/{IMAGE_DIR}/{name}\"\n",
    "        dest = os.path.join(IMAGE_DIR, name)\n",
    "        if not os.path.exists(dest):\n",
    "            print(f\"Downloading {name} ...\")\n",
    "            urllib.request.urlretrieve(url, dest)\n",
    "    # Bilateral filter figure (used in Final Challenge)\n",
    "    bf_url = f\"{REPO_URL}/week4/{BF_FIG_NAME}\"\n",
    "    if not os.path.exists(BF_FIG_NAME):\n",
    "        print(f\"Downloading {BF_FIG_NAME} ...\")\n",
    "        urllib.request.urlretrieve(bf_url, BF_FIG_NAME)\n",
    "    IMAGE_PATH = os.path.join(IMAGE_DIR, COLOR_NAME)\n",
    "    GRAY_PATH = os.path.join(IMAGE_DIR, GRAY_NAME)\n",
    "    BF_FIG_PATH = BF_FIG_NAME\n",
    "else:\n",
    "    IMAGE_PATH = os.path.join(\"..\", IMAGE_DIR, COLOR_NAME)\n",
    "    GRAY_PATH = os.path.join(\"..\", IMAGE_DIR, GRAY_NAME)\n",
    "    BF_FIG_PATH = BF_FIG_NAME\n",
    "\n",
    "print(f\"Image path: {IMAGE_PATH}\")\n",
    "print(f\"Running on: {'Google Colab' if IN_COLAB else 'Local'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display helpers\n",
    "\n",
    "Utility functions used throughout this notebook. This week adds `show_denoising_comparison` for comparing denoised results with quality metric annotations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_images(*imgs, titles=None, scale=4):\n",
    "    \"\"\"Display images in a single row.\n",
    "\n",
    "    Grayscale (2-D) arrays automatically use a gray colormap.\n",
    "    *titles* is an optional list of strings, one per image.\n",
    "    \"\"\"\n",
    "    n = len(imgs)\n",
    "    fig, axes = plt.subplots(1, n, figsize=(scale * n, scale))\n",
    "    if n == 1:\n",
    "        axes = [axes]\n",
    "    for i, (ax, img) in enumerate(zip(axes, imgs)):\n",
    "        if img.ndim == 2:\n",
    "            ax.imshow(img, cmap=\"gray\", vmin=0, vmax=255)\n",
    "        else:\n",
    "            ax.imshow(img)\n",
    "        if titles:\n",
    "            ax.set_title(titles[i])\n",
    "        ax.axis(\"off\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def show_denoising_comparison(original, results, titles, scale=4):\n",
    "    \"\"\"Display denoised results with PSNR and SSIM annotations.\n",
    "\n",
    "    *original* is the clean reference image.\n",
    "    *results*  is a list of denoised images.\n",
    "    *titles*   is a list of names (one per result).\n",
    "    \"\"\"\n",
    "    n = len(results)\n",
    "    fig, axes = plt.subplots(1, n, figsize=(scale * n, scale + 0.6))\n",
    "    if n == 1:\n",
    "        axes = [axes]\n",
    "    for ax, img, title in zip(axes, results, titles):\n",
    "        ax.imshow(img, cmap=\"gray\", vmin=0, vmax=255)\n",
    "        psnr = peak_signal_noise_ratio(original, img)\n",
    "        ssim = structural_similarity(original, img)\n",
    "        ax.set_title(f\"{title}\\nPSNR={psnr:.2f} dB  SSIM={ssim:.3f}\", fontsize=10)\n",
    "        ax.axis(\"off\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def show_kernel(kernel, title=\"Kernel\", ax=None):\n",
    "    \"\"\"Display a small kernel as an annotated heatmap.\"\"\"\n",
    "    standalone = ax is None\n",
    "    if standalone:\n",
    "        fig, ax = plt.subplots(figsize=(3, 3))\n",
    "    vmax = np.max(np.abs(kernel))\n",
    "    ax.imshow(kernel, cmap=\"coolwarm\", vmin=-vmax, vmax=vmax)\n",
    "    for i in range(kernel.shape[0]):\n",
    "        for j in range(kernel.shape[1]):\n",
    "            val = kernel[i, j]\n",
    "            text = f\"{val:.2f}\" if val != int(val) else str(int(val))\n",
    "            ax.text(j, i, text, ha=\"center\", va=\"center\", fontsize=10)\n",
    "    ax.set_title(title)\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "    if standalone:\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "def show_kernels(*kernels, titles=None):\n",
    "    \"\"\"Display multiple kernels as annotated heatmaps in a row.\"\"\"\n",
    "    n = len(kernels)\n",
    "    fig, axes = plt.subplots(1, n, figsize=(3 * n, 3))\n",
    "    if n == 1:\n",
    "        axes = [axes]\n",
    "    for i, (ax, k) in enumerate(zip(axes, kernels)):\n",
    "        show_kernel(k, title=titles[i] if titles else \"Kernel\", ax=ax)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def show_kernel_3d(kernel, title=\"\"):\n",
    "    \"\"\"Display a kernel as a 3D surface plot.\"\"\"\n",
    "    k = kernel.shape[0] // 2\n",
    "    ax_range = np.arange(-k, k + 1)\n",
    "    xx, yy = np.meshgrid(ax_range, ax_range)\n",
    "    fig = plt.figure(figsize=(6, 5))\n",
    "    ax = fig.add_subplot(111, projection=\"3d\")\n",
    "    ax.plot_surface(xx, yy, kernel, cmap=\"viridis\")\n",
    "    if title:\n",
    "        ax.set_title(title)\n",
    "    ax.set_xlabel(\"x\")\n",
    "    ax.set_ylabel(\"y\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def show_maps(*maps, titles=None, scale=4):\n",
    "    \"\"\"Display 2D float arrays with auto grayscale mapping.\"\"\"\n",
    "    n = len(maps)\n",
    "    fig, axes = plt.subplots(1, n, figsize=(scale * n, scale))\n",
    "    if n == 1:\n",
    "        axes = [axes]\n",
    "    for i, (ax, m) in enumerate(zip(axes, maps)):\n",
    "        ax.imshow(m, cmap=\"gray\")\n",
    "        if titles:\n",
    "            ax.set_title(titles[i])\n",
    "        ax.axis(\"off\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def rescale_for_display(img):\n",
    "    \"\"\"Rescale a float image to [0, 255] uint8 for display.\"\"\"\n",
    "    lo, hi = img.min(), img.max()\n",
    "    if hi - lo == 0:\n",
    "        return np.zeros_like(img, dtype=np.uint8)\n",
    "    return ((img - lo) / (hi - lo) * 255).astype(np.uint8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 1. Aliasing\n",
    "\n",
    "When we downsample an image by simply skipping pixels, high-frequency content can **fold back** into the low-frequency range, creating false patterns called **aliasing artifacts** (Moiré patterns, jaggies).\n",
    "\n",
    "The fix: apply a **low-pass filter** (e.g., Gaussian blur) before downsampling to remove frequencies above the new Nyquist limit.\n",
    "\n",
    "$$\\sigma \\approx \\frac{\\text{factor}}{2}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_color = np.array(Image.open(IMAGE_PATH))\n",
    "img_gray = np.array(Image.open(GRAY_PATH))\n",
    "\n",
    "print(f\"Color \\u2014 shape: {img_color.shape}, dtype: {img_color.dtype}\")\n",
    "print(f\"Gray  \\u2014 shape: {img_gray.shape}, dtype: {img_gray.dtype}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Zone plate: aliasing in action\n",
    "\n",
    "A **zone plate** contains concentric circles with increasing frequency toward the edges — a perfect test for aliasing. When we naively downsample, the high-frequency rings produce false Moiré patterns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a zone plate (concentric circles with increasing frequency)\n",
    "size = 256\n",
    "x = np.linspace(-1, 1, size)\n",
    "xx, yy = np.meshgrid(x, x)\n",
    "zone_plate = (np.cos(80 * np.pi * (xx**2 + yy**2)) * 127.5 + 127.5).astype(np.uint8)\n",
    "\n",
    "# Naive downsample: just skip pixels\n",
    "factor = 4\n",
    "naive_down = zone_plate[::factor, ::factor]\n",
    "\n",
    "show_images(zone_plate, naive_down,\n",
    "            titles=[f\"Zone plate ({size}\\u00d7{size})\",\n",
    "                    f\"Naive \\u00d7{factor} downsample ({naive_down.shape[0]}\\u00d7{naive_down.shape[1]})\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Anti-aliased downsampling\n",
    "\n",
    "Apply a Gaussian blur **before** downsampling to remove high frequencies that would otherwise fold back."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "factor = 4\n",
    "sigma = factor / 2.0\n",
    "\n",
    "# Step 1: Low-pass filter\n",
    "blurred = gaussian_filter(img_gray.astype(np.float64), sigma=sigma)\n",
    "blurred = np.clip(blurred, 0, 255).astype(np.uint8)\n",
    "\n",
    "# Step 2: Downsample\n",
    "naive_down = img_gray[::factor, ::factor]\n",
    "aa_down = blurred[::factor, ::factor]\n",
    "\n",
    "show_images(img_gray, naive_down, aa_down,\n",
    "            titles=[\"Original\",\n",
    "                    f\"Naive \\u00d7{factor}\",\n",
    "                    f\"Anti-aliased \\u00d7{factor} (\\u03c3={sigma})\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 2. Image Noise\n",
    "\n",
    "Real images are always contaminated by noise. The basic noise model:\n",
    "\n",
    "$$g(x,y) = f(x,y) + n(x,y)$$\n",
    "\n",
    "where $f$ is the clean image and $n$ is the noise. Two common types:\n",
    "- **Gaussian noise**: $n(x,y) \\sim \\mathcal N(0, \\sigma^2)$ — additive, affects every pixel a little bit\n",
    "- **Salt & Pepper noise**: random pixels flipped to 0 (pepper) or 255 (salt) — sparse but extreme"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gaussian noise\n",
    "\n",
    "Each pixel gets a small random perturbation drawn from a normal distribution. The parameter $\\sigma$ controls the noise intensity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_gaussian_noise(img, sigma):\n",
    "    \"\"\"Add Gaussian noise with standard deviation *sigma* to an image.\"\"\"\n",
    "    noise = np.random.normal(0, sigma, img.shape)\n",
    "    return np.clip(img.astype(np.float64) + noise, 0, 255).astype(np.uint8)\n",
    "\n",
    "np.random.seed(42)\n",
    "sigmas = [10, 25, 50]\n",
    "gauss_noisy = [add_gaussian_noise(img_gray, s) for s in sigmas]\n",
    "\n",
    "show_images(img_gray, *gauss_noisy,\n",
    "            titles=[\"Original\"] + [f\"\\u03c3 = {s}\" for s in sigmas])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Salt & Pepper noise\n",
    "\n",
    "Random pixels are set to the extreme values 0 or 255. The parameter controls the **density** (fraction of affected pixels)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_salt_pepper_noise(img, density):\n",
    "    \"\"\"Add salt & pepper noise with the given *density* (fraction of affected pixels).\"\"\"\n",
    "    noisy = img.copy()\n",
    "    mask = np.random.random(img.shape)\n",
    "    noisy[mask < density / 2] = 0        # pepper\n",
    "    noisy[mask > 1 - density / 2] = 255  # salt\n",
    "    return noisy\n",
    "\n",
    "np.random.seed(42)\n",
    "densities = [0.05, 0.10, 0.20]\n",
    "sp_noisy = [add_salt_pepper_noise(img_gray, d) for d in densities]\n",
    "\n",
    "show_images(img_gray, *sp_noisy,\n",
    "            titles=[\"Original\"] + [f\"Density = {d:.0%}\" for d in densities])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Side-by-side comparison\n",
    "\n",
    "Gaussian noise looks like an overall **grainy texture**, while Salt & Pepper appears as scattered **black and white speckles**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "noisy_gauss = add_gaussian_noise(img_gray, 25)\n",
    "noisy_sp = add_salt_pepper_noise(img_gray, 0.10)\n",
    "\n",
    "show_images(img_gray, noisy_gauss, noisy_sp,\n",
    "            titles=[\"Original\", \"Gaussian (\\u03c3=25)\", \"Salt & Pepper (10%)\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 3. Image Denoising\n",
    "\n",
    "Different noise types call for different filters:\n",
    "- **Gaussian noise** → Mean or Gaussian filter (averaging reduces variance)\n",
    "- **Salt & Pepper noise** → Median filter (outliers can never become the median)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mean and Gaussian filter for Gaussian noise\n",
    "\n",
    "Averaging $N$ independent noisy samples reduces variance by $N$:\n",
    "\n",
    "$$\\text{Var}(\\bar{n}) = \\frac{\\sigma^2}{N}$$\n",
    "\n",
    "A $5 \\times 5$ mean filter averages 25 pixels, reducing noise $\\sigma$ by a factor of $\\sqrt{25} = 5$.\n",
    "\n",
    "A Gaussian filter gives **higher weight to closer neighbors**, producing a smoother result than the box filter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "noisy_gauss = add_gaussian_noise(img_gray, 25)\n",
    "\n",
    "denoised_mean = uniform_filter(noisy_gauss.astype(np.float64), size=5)\n",
    "denoised_mean = np.clip(denoised_mean, 0, 255).astype(np.uint8)\n",
    "\n",
    "denoised_gauss = gaussian_filter(noisy_gauss.astype(np.float64), sigma=1.5)\n",
    "denoised_gauss = np.clip(denoised_gauss, 0, 255).astype(np.uint8)\n",
    "\n",
    "show_images(img_gray, noisy_gauss, denoised_mean, denoised_gauss,\n",
    "            titles=[\"Original\", \"Noisy (\\u03c3=25)\", \"Mean 5\\u00d75\", \"Gaussian (\\u03c3=1.5)\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Median filter for Salt & Pepper noise\n",
    "\n",
    "The median filter sorts the neighborhood values and picks the **middle one**. Salt (255) or pepper (0) pixels are extreme outliers and can never become the median in a mostly-clean neighborhood.\n",
    "\n",
    "The median filter is **non-linear** — it is NOT a convolution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "noisy_sp = add_salt_pepper_noise(img_gray, 0.10)\n",
    "\n",
    "denoised_median = median_filter(noisy_sp, size=5)\n",
    "\n",
    "show_images(img_gray, noisy_sp, denoised_median,\n",
    "            titles=[\"Original\", \"S&P (10%)\", \"Median 5\\u00d75\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wrong tool: mean filter on Salt & Pepper\n",
    "\n",
    "What happens when we apply a **mean filter** to Salt & Pepper noise? Each salt pixel (255) gets **averaged** into its neighbors, spreading the extreme value into a gray blob instead of removing it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "noisy_sp = add_salt_pepper_noise(img_gray, 0.10)\n",
    "\n",
    "mean_on_sp = uniform_filter(noisy_sp.astype(np.float64), size=5)\n",
    "mean_on_sp = np.clip(mean_on_sp, 0, 255).astype(np.uint8)\n",
    "\n",
    "median_on_sp = median_filter(noisy_sp, size=5)\n",
    "\n",
    "show_images(noisy_sp, mean_on_sp, median_on_sp,\n",
    "            titles=[\"S&P (10%)\", \"Mean 5\\u00d75 (smears!)\", \"Median 5\\u00d75 (clean)\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visual comparison: all combinations\n",
    "\n",
    "Let's see how each filter performs on each noise type. This 2\\u00d73 grid shows the strengths and weaknesses of each approach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "noisy_gauss = add_gaussian_noise(img_gray, 25)\n",
    "noisy_sp = add_salt_pepper_noise(img_gray, 0.10)\n",
    "\n",
    "# Apply all three filters to both noise types\n",
    "results = {}\n",
    "for name, noisy in [(\"Gaussian noise\", noisy_gauss), (\"S&P noise\", noisy_sp)]:\n",
    "    mean_r = np.clip(uniform_filter(noisy.astype(np.float64), size=5), 0, 255).astype(np.uint8)\n",
    "    gauss_r = np.clip(gaussian_filter(noisy.astype(np.float64), sigma=1.5), 0, 255).astype(np.uint8)\n",
    "    median_r = median_filter(noisy, size=5)\n",
    "    results[name] = {\"Noisy\": noisy, \"Mean 5\\u00d75\": mean_r, \"Gaussian \\u03c3=1.5\": gauss_r, \"Median 5\\u00d75\": median_r}\n",
    "\n",
    "fig, axes = plt.subplots(2, 4, figsize=(16, 8.5))\n",
    "for row, (noise_type, imgs) in enumerate(results.items()):\n",
    "    for col, (label, img) in enumerate(imgs.items()):\n",
    "        axes[row, col].imshow(img, cmap=\"gray\", vmin=0, vmax=255)\n",
    "        axes[row, col].set_title(label, fontsize=11)\n",
    "        axes[row, col].axis(\"off\")\n",
    "    axes[row, 0].set_ylabel(noise_type, fontsize=12, rotation=90, labelpad=10)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 4. Quality Metrics\n",
    "\n",
    "How do we **quantify** how good a denoised image is? We need metrics that compare the result to the clean original.\n",
    "\n",
    "Three common metrics:\n",
    "- **MSE** (Mean Squared Error) — average squared pixel difference\n",
    "- **PSNR** (Peak Signal-to-Noise Ratio) — MSE on a log (dB) scale\n",
    "- **SSIM** (Structural Similarity) — perceptual quality based on local statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MSE and PSNR\n",
    "\n",
    "$$\\text{MSE} = \\frac{1}{HW}\\sum_{x,y}\\big[f(x,y) - \\hat{f}(x,y)\\big]^2$$\n",
    "\n",
    "$$\\text{PSNR} = 10 \\cdot \\log_{10}\\!\\left(\\frac{255^2}{\\text{MSE}}\\right) \\;\\text{dB}$$\n",
    "\n",
    "PSNR is just MSE on a logarithmic scale. **Higher is better.** Rule of thumb: >30 dB is good quality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "noisy_gauss = add_gaussian_noise(img_gray, 25)\n",
    "\n",
    "# Compute from scratch\n",
    "diff = img_gray.astype(np.float64) - noisy_gauss.astype(np.float64)\n",
    "mse = np.mean(diff ** 2)\n",
    "psnr_manual = 10 * np.log10(255**2 / mse)\n",
    "\n",
    "# Using skimage\n",
    "psnr_skimage = peak_signal_noise_ratio(img_gray, noisy_gauss)\n",
    "\n",
    "print(f\"MSE  = {mse:.2f}\")\n",
    "print(f\"PSNR (manual)  = {psnr_manual:.2f} dB\")\n",
    "print(f\"PSNR (skimage) = {psnr_skimage:.2f} dB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SSIM\n",
    "\n",
    "SSIM compares images using **local statistics** (mean, variance, covariance) within a sliding window. It captures luminance, contrast, and structural similarity separately.\n",
    "\n",
    "$$\\text{SSIM}(x,y) = \\frac{(2\\mu_x\\mu_y + C_1)(2\\sigma_{xy} + C_2)}{(\\mu_x^2 + \\mu_y^2 + C_1)(\\sigma_x^2 + \\sigma_y^2 + C_2)}$$\n",
    "\n",
    "- Range: $[0, 1]$, where 1 = identical\n",
    "- Closer to human perception than MSE/PSNR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ssim_value = structural_similarity(img_gray, noisy_gauss)\n",
    "print(f\"SSIM (global) = {ssim_value:.4f}\")\n",
    "\n",
    "# SSIM map: local SSIM at each pixel\n",
    "_, ssim_map = structural_similarity(img_gray, noisy_gauss, full=True)\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(14, 4))\n",
    "axes[0].imshow(img_gray, cmap=\"gray\", vmin=0, vmax=255)\n",
    "axes[0].set_title(\"Original\")\n",
    "axes[1].imshow(noisy_gauss, cmap=\"gray\", vmin=0, vmax=255)\n",
    "axes[1].set_title(f\"Noisy (PSNR={psnr_skimage:.1f} dB)\")\n",
    "im = axes[2].imshow(ssim_map, cmap=\"hot\", vmin=0, vmax=1)\n",
    "axes[2].set_title(f\"SSIM map (mean={ssim_value:.3f})\")\n",
    "plt.colorbar(im, ax=axes[2], fraction=0.046)\n",
    "for ax in axes:\n",
    "    ax.axis(\"off\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating denoising with metrics\n",
    "\n",
    "Now let's **quantify** the visual comparison from Section 3 using PSNR and SSIM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "noisy_gauss = add_gaussian_noise(img_gray, 25)\n",
    "noisy_sp = add_salt_pepper_noise(img_gray, 0.10)\n",
    "\n",
    "# Denoise Gaussian noise\n",
    "gauss_denoised = np.clip(\n",
    "    gaussian_filter(noisy_gauss.astype(np.float64), sigma=1.0), 0, 255\n",
    ").astype(np.uint8)\n",
    "\n",
    "# Denoise S&P noise\n",
    "sp_denoised = median_filter(noisy_sp, size=3)\n",
    "\n",
    "print(\"=== Gaussian noise ===\")\n",
    "show_denoising_comparison(\n",
    "    img_gray,\n",
    "    [noisy_gauss, gauss_denoised],\n",
    "    [\"Noisy\", \"Gaussian \\u03c3=1.0\"]\n",
    ")\n",
    "\n",
    "print(\"=== Salt & Pepper noise ===\")\n",
    "show_denoising_comparison(\n",
    "    img_gray,\n",
    "    [noisy_sp, sp_denoised],\n",
    "    [\"Noisy\", \"Median 3\\u00d73\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 4.1:** Apply a **Gaussian filter** ($\\sigma=1.0$) and a **Median filter** (size=3) to both `noisy_gauss` (Gaussian noise, $\\sigma=25$) and `noisy_sp` (Salt & Pepper, 10%).\n",
    "\n",
    "For each of the 4 combinations, compute the PSNR against the original image (`img_gray`). Display all four results using `show_denoising_comparison`. Which filter works best for which noise type?\n",
    "\n",
    "*Hint:* Use `gaussian_filter` and `median_filter` from scipy, and `peak_signal_noise_ratio` from skimage. The helper `show_denoising_comparison(img_gray, [result1, result2], [\"Title1\", \"Title2\"])` will display PSNR and SSIM automatically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "\n",
    "\n",
    "# Which filter works best for which noise type? Why?\n",
    "# (You may write your answer in Korean.)\n",
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 4.2:** Given `noisy_gauss` (Gaussian noise, $\\sigma=25$), sweep the Gaussian filter's $\\sigma$ across the values `[0.5, 1.0, 1.5, 2.0, 2.5, 3.0, 4.0, 5.0]`. For each $\\sigma$, denoise the image and compute PSNR.\n",
    "\n",
    "1. Plot $\\sigma$ vs PSNR (use `plt.plot`)\n",
    "2. Find the optimal $\\sigma$ (highest PSNR)\n",
    "3. Display three images: original (`img_gray`), noisy, and best-denoised\n",
    "\n",
    "*Hint:* Use `gaussian_filter(noisy.astype(np.float64), sigma=s)`, clip to [0, 255], and cast to uint8. The optimal $\\sigma$ is the one that maximizes PSNR."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 5. Edge Detection\n",
    "\n",
    "An **edge** is a significant local change in intensity. We detect edges by computing **derivatives** of the image.\n",
    "\n",
    "The **gradient** at each pixel:\n",
    "\n",
    "$$\\nabla f = \\begin{bmatrix} G_x \\\\ G_y \\end{bmatrix} \\quad\\quad\n",
    "\\text{Magnitude: } |\\nabla f| = \\sqrt{G_x^2 + G_y^2} \\quad\\quad\n",
    "\\text{Direction: } \\theta = \\arctan\\!\\left(\\frac{G_y}{G_x}\\right)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1D derivative intuition\n",
    "\n",
    "Before working with 2D images, let's look at how derivatives detect edges in a 1D signal. The **first derivative** peaks at edges, while the **second derivative** crosses zero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract a horizontal line from the image\n",
    "row = 128\n",
    "profile = img_gray[row, :].astype(np.float64)\n",
    "\n",
    "# 1st derivative (central difference)\n",
    "d1 = np.convolve(profile, [-1, 0, 1], mode=\"same\")\n",
    "\n",
    "# 2nd derivative\n",
    "d2 = np.convolve(profile, [1, -2, 1], mode=\"same\")\n",
    "\n",
    "fig, axes = plt.subplots(3, 1, figsize=(10, 7), sharex=True)\n",
    "axes[0].plot(profile)\n",
    "axes[0].set_ylabel(\"Intensity\")\n",
    "axes[0].set_title(f\"1D profile (row {row})\")\n",
    "\n",
    "axes[1].plot(d1)\n",
    "axes[1].axhline(0, color=\"gray\", linewidth=0.5)\n",
    "axes[1].set_ylabel(\"1st derivative\")\n",
    "axes[1].set_title(\"First derivative (peaks at edges)\")\n",
    "\n",
    "axes[2].plot(d2)\n",
    "axes[2].axhline(0, color=\"gray\", linewidth=0.5)\n",
    "axes[2].set_ylabel(\"2nd derivative\")\n",
    "axes[2].set_title(\"Second derivative (zero crossings at edges)\")\n",
    "axes[2].set_xlabel(\"Column\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sobel operator (1st derivative)\n",
    "\n",
    "The Sobel operator computes the image gradient using two 3\\u00d73 kernels. Each kernel combines **smoothing** in one direction with a **derivative** in the other:\n",
    "\n",
    "$$G_x = \\begin{bmatrix}-1 & 0 & 1\\\\-2 & 0 & 2\\\\-1 & 0 & 1\\end{bmatrix} \\quad\\quad\n",
    "G_y = \\begin{bmatrix}-1 & -2 & -1\\\\0 & 0 & 0\\\\1 & 2 & 1\\end{bmatrix}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sobel_x = np.array([[-1, 0, 1],\n",
    "                     [-2, 0, 2],\n",
    "                     [-1, 0, 1]], dtype=np.float64)\n",
    "\n",
    "sobel_y = np.array([[-1, -2, -1],\n",
    "                     [ 0,  0,  0],\n",
    "                     [ 1,  2,  1]], dtype=np.float64)\n",
    "\n",
    "show_kernels(sobel_x, sobel_y, titles=[\"Sobel $G_x$\", \"Sobel $G_y$\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gx = correlate(img_gray.astype(np.float64), sobel_x, mode=\"constant\", cval=0)\n",
    "gy = correlate(img_gray.astype(np.float64), sobel_y, mode=\"constant\", cval=0)\n",
    "magnitude = np.sqrt(gx**2 + gy**2)\n",
    "\n",
    "show_images(img_gray, rescale_for_display(gx), rescale_for_display(gy), rescale_for_display(magnitude),\n",
    "            titles=[\"Original\", \"$G_x$ (horizontal edges)\", \"$G_y$ (vertical edges)\", \"Magnitude\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Laplacian (2nd derivative)\n",
    "\n",
    "The Laplacian computes the sum of second partial derivatives using a **single kernel**. Edges appear as **zero crossings**.\n",
    "\n",
    "$$\\nabla^2 f = \\frac{\\partial^2 f}{\\partial x^2} + \\frac{\\partial^2 f}{\\partial y^2}$$\n",
    "\n",
    "Two variants:\n",
    "- **4-connected**: $\\begin{bmatrix}0 & 1 & 0\\\\1 & -4 & 1\\\\0 & 1 & 0\\end{bmatrix}$ — horizontal & vertical\n",
    "- **8-connected**: $\\begin{bmatrix}1 & 1 & 1\\\\1 & -8 & 1\\\\1 & 1 & 1\\end{bmatrix}$ — includes diagonals (more isotropic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lap4 = np.array([[0,  1, 0],\n",
    "                  [1, -4, 1],\n",
    "                  [0,  1, 0]], dtype=np.float64)\n",
    "\n",
    "lap8 = np.array([[1,  1, 1],\n",
    "                  [1, -8, 1],\n",
    "                  [1,  1, 1]], dtype=np.float64)\n",
    "\n",
    "edges4 = correlate(img_gray.astype(np.float64), lap4, mode=\"constant\", cval=0)\n",
    "edges8 = correlate(img_gray.astype(np.float64), lap8, mode=\"constant\", cval=0)\n",
    "\n",
    "show_images(img_gray, rescale_for_display(edges4), rescale_for_display(edges8),\n",
    "            titles=[\"Original\", \"Laplacian (4-connected)\", \"Laplacian (8-connected)\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Laplacian of Gaussian (LoG)\n",
    "\n",
    "Raw derivatives amplify noise. The solution: **smooth first, then differentiate**. By linearity, we can combine these into a single kernel:\n",
    "\n",
    "$$\\nabla^2(G_\\sigma * f) = (\\nabla^2 G_\\sigma) * f$$\n",
    "\n",
    "The LoG kernel has a characteristic **Mexican hat** shape: a positive center surrounded by a negative ring."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_log_kernel(size, sigma):\n",
    "    \"\"\"Create a Laplacian of Gaussian (LoG) kernel.\"\"\"\n",
    "    k = size // 2\n",
    "    ax = np.arange(-k, k + 1, dtype=np.float64)\n",
    "    xx, yy = np.meshgrid(ax, ax)\n",
    "    r2 = xx**2 + yy**2\n",
    "    # LoG formula\n",
    "    kernel = -(1 / (np.pi * sigma**4)) * (1 - r2 / (2 * sigma**2)) * np.exp(-r2 / (2 * sigma**2))\n",
    "    kernel -= kernel.mean()  # ensure zero-sum\n",
    "    return kernel\n",
    "\n",
    "log_kernel = make_log_kernel(15, sigma=2.0)\n",
    "show_kernel_3d(log_kernel, title=\"LoG kernel (\\u03c3=2.0) \\u2014 Mexican hat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_edges = correlate(img_gray.astype(np.float64), log_kernel, mode=\"constant\", cval=0)\n",
    "\n",
    "show_images(img_gray, rescale_for_display(log_edges),\n",
    "            titles=[\"Original\", \"LoG edges (\\u03c3=2.0)\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Canny edge detection\n",
    "\n",
    "The Canny detector is a complete **pipeline** that produces clean, thin, connected edges:\n",
    "\n",
    "1. **Gaussian blur** — smooth the image (controlled by $\\sigma$)\n",
    "2. **Gradient computation** — Sobel for magnitude and direction\n",
    "3. **Non-maximum suppression** — keep only local maxima along the gradient direction → 1-pixel-thin edges\n",
    "4. **Hysteresis thresholding** — two thresholds ($T_\\text{high}$, $T_\\text{low}$) connect strong and weak edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Canny expects float image in [0, 1]\n",
    "img_float = img_gray / 255.0\n",
    "\n",
    "edges_s1 = canny(img_float, sigma=1.0).astype(np.uint8) * 255\n",
    "edges_s2 = canny(img_float, sigma=2.0).astype(np.uint8) * 255\n",
    "edges_s4 = canny(img_float, sigma=4.0).astype(np.uint8) * 255\n",
    "\n",
    "show_images(img_gray, edges_s1, edges_s2, edges_s4,\n",
    "            titles=[\"Original\", \"Canny \\u03c3=1.0\", \"Canny \\u03c3=2.0\", \"Canny \\u03c3=4.0\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparison: Sobel vs Laplacian vs LoG vs Canny"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sobel_mag = rescale_for_display(np.sqrt(\n",
    "    correlate(img_gray.astype(np.float64), sobel_x, mode=\"constant\", cval=0)**2 +\n",
    "    correlate(img_gray.astype(np.float64), sobel_y, mode=\"constant\", cval=0)**2\n",
    "))\n",
    "lap_result = rescale_for_display(correlate(img_gray.astype(np.float64), lap4, mode=\"constant\", cval=0))\n",
    "log_result = rescale_for_display(correlate(img_gray.astype(np.float64), make_log_kernel(15, 2.0), mode=\"constant\", cval=0))\n",
    "canny_result = canny(img_gray / 255.0, sigma=2.0).astype(np.uint8) * 255\n",
    "\n",
    "show_images(sobel_mag, lap_result, log_result, canny_result,\n",
    "            titles=[\"Sobel magnitude\", \"Laplacian\", \"LoG (\\u03c3=2)\", \"Canny (\\u03c3=2)\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 5.1:** Apply the Sobel operator to the grayscale image (`img_gray`) to compute $G_x$ and $G_y$. Then compute:\n",
    "- **Gradient magnitude**: $|\\nabla f| = \\sqrt{G_x^2 + G_y^2}$\n",
    "- **Gradient direction**: $\\theta = \\text{arctan2}(G_y,\\, G_x)$\n",
    "\n",
    "Display three images side by side: the original, the gradient magnitude, and the gradient direction.\n",
    "\n",
    "*Hint:* Use `sobel_x`, `sobel_y` with `scipy.ndimage.correlate`. For direction, use `np.arctan2(gy, gx)`. Display the magnitude with `rescale_for_display` and the direction with `cmap='hsv'` (since angles map naturally to a circular colormap)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 5.2:** Add Gaussian noise ($\\sigma=30$) to `img_gray`. Then apply four edge detectors to the **noisy** image and display the results:\n",
    "\n",
    "1. **Sobel** magnitude ($\\sqrt{G_x^2 + G_y^2}$)\n",
    "2. **Laplacian** (4-connected kernel `lap4`)\n",
    "3. **LoG** (use `make_log_kernel(15, 2.0)`)\n",
    "4. **Canny** (`canny(img / 255.0, sigma=2.0)`)\n",
    "\n",
    "Which operators handle noise well, and which ones break down? Why?\n",
    "\n",
    "*Hint:* Use `add_gaussian_noise`, the Sobel/Laplacian/LoG patterns from the demos above, and `rescale_for_display` for Sobel/Laplacian/LoG results. Canny returns a boolean array — multiply by 255 for display."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "\n",
    "\n",
    "# Which operators handle noise well? Why?\n",
    "# (You may write your answer in Korean.)\n",
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Final Challenge\n",
    "\n",
    "### Bilateral Filter: Edge-Preserving Denoising\n",
    "\n",
    "All the filters we have used so far (mean, Gaussian, median) share a common limitation: they smooth **everything**, including edges. The Gaussian filter, for example, reduces noise but also blurs sharp boundaries.\n",
    "\n",
    "The **bilateral filter** solves this by using two Gaussian weights:\n",
    "- **Spatial weight** $G_{\\sigma_s}(\\|p - q\\|)$ — nearby pixels contribute more (same as Gaussian filter)\n",
    "- **Range weight** $G_{\\sigma_r}(|I_p - I_q|)$ — pixels with **similar intensity** contribute more\n",
    "\n",
    "$$\\text{BF}[I]_p = \\frac{1}{W_p}\\sum_{q \\in \\mathcal N(p)} G_{\\sigma_s}(\\|p-q\\|)\\;\\cdot\\;G_{\\sigma_r}(|I_p - I_q|)\\;\\cdot\\;I_q$$\n",
    "\n",
    "where $W_p = \\sum_q G_{\\sigma_s} \\cdot G_{\\sigma_r}$ is a normalization factor.\n",
    "\n",
    "**Key insight**: At an edge, pixels on the opposite side have very different intensity, so their range weight becomes near-zero. The filter effectively **stops at edges** while still averaging similar pixels.\n",
    "\n",
    "The figure below (from Durand & Dorsey, 2002) illustrates the bilateral filtering process for a single pixel:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bf_fig = Image.open(BF_FIG_PATH)\n",
    "fig, ax = plt.subplots(figsize=(14, 3))\n",
    "ax.imshow(bf_fig)\n",
    "ax.axis(\"off\")\n",
    "ax.set_title(\"Bilateral filtering: input \\u2192 spatial kernel \\u2192 range kernel \\u2192 combined weight \\u2192 output\",\n",
    "             fontsize=11)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your task:** Complete the `bilateral_filter` function below. The outer loop, padding, and spatial weight precomputation are provided. You need to fill in the **4 lines** inside the loop:\n",
    "\n",
    "1. Compute **range weights**: apply a Gaussian to the intensity difference between each neighbor and the center pixel\n",
    "2. Combine spatial and range weights\n",
    "3. Normalize so the weights sum to 1\n",
    "4. Compute the weighted average\n",
    "\n",
    "Then apply your bilateral filter to a noisy image and compare with a standard Gaussian filter using PSNR.\n",
    "\n",
    "*Hint:* The range weight for each neighbor is $\\exp\\!\\left(-\\frac{(I_\\text{neighbor} - I_\\text{center})^2}{2\\sigma_r^2}\\right)$. You can compute this for the entire neighborhood array at once using NumPy broadcasting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bilateral_filter(img, d=5, sigma_s=2.0, sigma_r=25.0):\n",
    "    \"\"\"Bilateral filter: edge-preserving denoising.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    img     : 2D uint8 array (grayscale image)\n",
    "    d       : kernel diameter (must be odd)\n",
    "    sigma_s : spatial Gaussian standard deviation\n",
    "    sigma_r : range (intensity) Gaussian standard deviation\n",
    "    \"\"\"\n",
    "    img_f = img.astype(np.float64)\n",
    "    h, w = img_f.shape\n",
    "    r = d // 2\n",
    "    output = np.zeros_like(img_f)\n",
    "\n",
    "    # Pre-compute spatial Gaussian weights (same for every pixel)\n",
    "    ax = np.arange(-r, r + 1, dtype=np.float64)\n",
    "    xx, yy = np.meshgrid(ax, ax)\n",
    "    spatial_weights = np.exp(-(xx**2 + yy**2) / (2 * sigma_s**2))\n",
    "\n",
    "    # Pad image for border handling\n",
    "    padded = np.pad(img_f, r, mode=\"reflect\")\n",
    "\n",
    "    for i in range(h):\n",
    "        for j in range(w):\n",
    "            # Extract the local neighborhood\n",
    "            neighborhood = padded[i : i + d, j : j + d]\n",
    "            center_val = img_f[i, j]\n",
    "\n",
    "            # YOUR CODE HERE\n",
    "            # 1. range_weights = Gaussian of (neighborhood - center_val)\n",
    "            # 2. combined_weights = spatial_weights * range_weights\n",
    "            # 3. Normalize combined_weights so they sum to 1\n",
    "            # 4. output[i, j] = weighted sum of neighborhood\n",
    "\n",
    "    return np.clip(output, 0, 255).astype(np.uint8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test your implementation and compare with a standard Gaussian filter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "# 1. Generate a noisy image: add_gaussian_noise(img_gray, 25) with np.random.seed(42)\n",
    "# 2. Apply your bilateral_filter (try d=5, sigma_s=2.0, sigma_r=25.0)\n",
    "# 3. Apply gaussian_filter with sigma=1.0 for comparison\n",
    "# 4. Use show_denoising_comparison to display: noisy, Gaussian-denoised, bilateral-denoised"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}