{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 4: Noise & Edge Detection — Lab Practice\n",
    "\n",
    "**Topics:** Aliasing, Image Noise, Image Denoising, Quality Metrics (PSNR / SSIM), Edge Detection\n",
    "\n",
    "This notebook accompanies the Week 4 lecture slides. We will observe aliasing artifacts, generate and denoise different types of noise, measure image quality with PSNR and SSIM, and explore edge detection operators from Sobel to Canny — all hands-on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Environment setup\n",
    "\n",
    "This notebook works both **locally** and on **Google Colab**.\n",
    "- **Local**: images are loaded from the repository’s `images/` folder.\n",
    "- **Colab**: images are automatically downloaded from GitHub on first run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, urllib.request\n",
    "\n",
    "# Detect Google Colab\n",
    "IN_COLAB = \"google.colab\" in str(get_ipython()) if hasattr(__builtins__, \"__IPYTHON__\") else False\n",
    "\n",
    "# Image paths\n",
    "REPO_URL = \"https://raw.githubusercontent.com/HyeongminLEE/image-processing-tutorial/main\"\n",
    "IMAGE_DIR = \"images\"\n",
    "COLOR_NAME = \"parrots_256.jpg\"\n",
    "GRAY_NAME = \"parrots_256_gray.jpg\"\n",
    "BF_FIG_NAME = \"bilateral_filter_fig6.png\"\n",
    "\n",
    "if IN_COLAB:\n",
    "    os.makedirs(IMAGE_DIR, exist_ok=True)\n",
    "    for name in [COLOR_NAME, GRAY_NAME]:\n",
    "        url = f\"{REPO_URL}/{IMAGE_DIR}/{name}\"\n",
    "        dest = os.path.join(IMAGE_DIR, name)\n",
    "        if not os.path.exists(dest):\n",
    "            print(f\"Downloading {name} ...\")\n",
    "            urllib.request.urlretrieve(url, dest)\n",
    "    # Bilateral filter figure (used in Final Challenge)\n",
    "    bf_url = f\"{REPO_URL}/week4/{BF_FIG_NAME}\"\n",
    "    if not os.path.exists(BF_FIG_NAME):\n",
    "        print(f\"Downloading {BF_FIG_NAME} ...\")\n",
    "        urllib.request.urlretrieve(bf_url, BF_FIG_NAME)\n",
    "    IMAGE_PATH = os.path.join(IMAGE_DIR, COLOR_NAME)\n",
    "    GRAY_PATH = os.path.join(IMAGE_DIR, GRAY_NAME)\n",
    "    BF_FIG_PATH = BF_FIG_NAME\n",
    "else:\n",
    "    IMAGE_PATH = os.path.join(\"..\", IMAGE_DIR, COLOR_NAME)\n",
    "    GRAY_PATH = os.path.join(\"..\", IMAGE_DIR, GRAY_NAME)\n",
    "    BF_FIG_PATH = BF_FIG_NAME\n",
    "\n",
    "print(f\"Image path: {IMAGE_PATH}\")\n",
    "print(f\"Running on: {'Google Colab' if IN_COLAB else 'Local'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display helpers\n",
    "\n",
    "Utility functions used throughout this notebook. This week adds `show_denoising_comparison` for comparing denoised results with quality metric annotations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "def show_images(*imgs, titles=None, scale=4):\n    \"\"\"Display images in a single row.\n\n    Grayscale (2-D) arrays automatically use a gray colormap.\n    *titles* is an optional list of strings, one per image.\n    \"\"\"\n    n = len(imgs)\n    fig, axes = plt.subplots(1, n, figsize=(scale * n, scale))\n    if n == 1:\n        axes = [axes]\n    for i, (ax, img) in enumerate(zip(axes, imgs)):\n        if img.ndim == 2:\n            ax.imshow(img, cmap=\"gray\", vmin=0, vmax=255)\n        else:\n            ax.imshow(img)\n        if titles:\n            ax.set_title(titles[i])\n        ax.axis(\"off\")\n    plt.tight_layout()\n    plt.show()\n\n\ndef show_denoising_comparison(original, results, titles, scale=4):\n    \"\"\"Display denoised results with PSNR and SSIM annotations.\n\n    *original* is the clean reference image.\n    *results*  is a list of denoised images.\n    *titles*   is a list of names (one per result).\n    \"\"\"\n    n = len(results)\n    fig, axes = plt.subplots(1, n, figsize=(scale * n, scale + 0.6))\n    if n == 1:\n        axes = [axes]\n    for ax, img, title in zip(axes, results, titles):\n        ax.imshow(img, cmap=\"gray\", vmin=0, vmax=255)\n        psnr = peak_signal_noise_ratio(original, img)\n        ssim = structural_similarity(original, img)\n        ax.set_title(f\"{title}\\nPSNR={psnr:.2f} dB  SSIM={ssim:.3f}\", fontsize=10)\n        ax.axis(\"off\")\n    plt.tight_layout()\n    plt.show()\n\n\ndef show_maps(*maps, titles=None, scale=4, cmap=\"gray\", colorbar=False):\n    \"\"\"Display 2D float arrays (heatmaps, spectra, masks, etc.).\n\n    *cmap* controls the colormap (e.g., \"gray\", \"hot\", \"hsv\").\n    Set *colorbar=True* to add a colorbar to each subplot.\n    \"\"\"\n    n = len(maps)\n    fig, axes = plt.subplots(1, n, figsize=(scale * n, scale))\n    if n == 1:\n        axes = [axes]\n    for i, (ax, m) in enumerate(zip(axes, maps)):\n        im = ax.imshow(m, cmap=cmap)\n        if titles:\n            ax.set_title(titles[i])\n        ax.axis(\"off\")\n        if colorbar:\n            plt.colorbar(im, ax=ax, fraction=0.046)\n    plt.tight_layout()\n    plt.show()\n\n\ndef show_row_profile(img, row, *ys, titles=None, ylabels=None, zero_line=False):\n    \"\"\"Display a grayscale image with a highlighted row, plus aligned 1D plots below.\n\n    The image is stretched horizontally (aspect='auto') so that column\n    positions align exactly with the line plots underneath.\n    \"\"\"\n    n_plots = len(ys)\n    fig, axes = plt.subplots(\n        n_plots + 1, 1, figsize=(10, 2.5 * n_plots + 3),\n        gridspec_kw={\"height_ratios\": [3] + [2.5] * n_plots},\n        sharex=True,\n    )\n\n    # Top: image with highlighted row\n    axes[0].imshow(img, cmap=\"gray\", vmin=0, vmax=255, aspect=\"auto\")\n    axes[0].axhline(row, color=\"red\", linewidth=1.5)\n    if titles:\n        axes[0].set_title(titles[0])\n    axes[0].set_ylabel(\"Row\")\n    axes[0].set_xlim(0, img.shape[1] - 1)\n\n    # Below: line plots\n    for i, y in enumerate(ys):\n        ax = axes[i + 1]\n        ax.plot(y)\n        if zero_line:\n            ax.axhline(0, color=\"gray\", linewidth=0.5)\n        if titles and i + 1 < len(titles):\n            ax.set_title(titles[i + 1])\n        if ylabels and i < len(ylabels):\n            ax.set_ylabel(ylabels[i])\n\n    axes[-1].set_xlabel(\"Column\")\n    plt.tight_layout()\n    plt.show()\n\n\ndef show_line_plots(*ys, titles=None, ylabels=None, xlabel=None, zero_line=False):\n    \"\"\"Display 1D signals as vertically stacked line plots.\n\n    Useful for comparing profiles, derivatives, or filter responses.\n    \"\"\"\n    n = len(ys)\n    fig, axes = plt.subplots(n, 1, figsize=(10, 2.5 * n), sharex=True)\n    if n == 1:\n        axes = [axes]\n    for i, (ax, y) in enumerate(zip(axes, ys)):\n        ax.plot(y)\n        if zero_line:\n            ax.axhline(0, color=\"gray\", linewidth=0.5)\n        if titles:\n            ax.set_title(titles[i])\n        if ylabels:\n            ax.set_ylabel(ylabels[i])\n    if xlabel:\n        axes[-1].set_xlabel(xlabel)\n    plt.tight_layout()\n    plt.show()\n\n\ndef show_figure(img, title=None, width=14):\n    \"\"\"Display a figure/diagram image at its native aspect ratio.\n\n    Unlike show_images (which uses a fixed square-ish layout), this function\n    respects the image's width-to-height ratio — ideal for wide diagrams.\n    \"\"\"\n    img_arr = np.array(img) if not isinstance(img, np.ndarray) else img\n    h, w = img_arr.shape[:2]\n    fig, ax = plt.subplots(figsize=(width, width * h / w))\n    ax.imshow(img_arr)\n    ax.axis(\"off\")\n    if title:\n        ax.set_title(title, fontsize=11)\n    plt.tight_layout()\n    plt.show()\n\n\ndef show_kernel(kernel, title=\"Kernel\", ax=None):\n    \"\"\"Display a small kernel as an annotated heatmap.\"\"\"\n    standalone = ax is None\n    if standalone:\n        fig, ax = plt.subplots(figsize=(3, 3))\n    vmax = np.max(np.abs(kernel))\n    ax.imshow(kernel, cmap=\"coolwarm\", vmin=-vmax, vmax=vmax)\n    for i in range(kernel.shape[0]):\n        for j in range(kernel.shape[1]):\n            val = kernel[i, j]\n            text = f\"{val:.2f}\" if val != int(val) else str(int(val))\n            ax.text(j, i, text, ha=\"center\", va=\"center\", fontsize=10)\n    ax.set_title(title)\n    ax.set_xticks([])\n    ax.set_yticks([])\n    if standalone:\n        plt.tight_layout()\n        plt.show()\n\n\ndef show_kernels(*kernels, titles=None):\n    \"\"\"Display multiple kernels as annotated heatmaps in a row.\"\"\"\n    n = len(kernels)\n    fig, axes = plt.subplots(1, n, figsize=(3 * n, 3))\n    if n == 1:\n        axes = [axes]\n    for i, (ax, k) in enumerate(zip(axes, kernels)):\n        show_kernel(k, title=titles[i] if titles else \"Kernel\", ax=ax)\n    plt.tight_layout()\n    plt.show()\n\n\ndef show_kernel_3d(kernel, title=\"\"):\n    \"\"\"Display a kernel as a 3D surface plot.\"\"\"\n    k = kernel.shape[0] // 2\n    ax_range = np.arange(-k, k + 1)\n    xx, yy = np.meshgrid(ax_range, ax_range)\n    fig = plt.figure(figsize=(6, 5))\n    ax = fig.add_subplot(111, projection=\"3d\")\n    ax.plot_surface(xx, yy, kernel, cmap=\"viridis\")\n    if title:\n        ax.set_title(title)\n    ax.set_xlabel(\"x\")\n    ax.set_ylabel(\"y\")\n    plt.tight_layout()\n    plt.show()\n\n\ndef rescale_for_display(img):\n    \"\"\"Rescale a float image to [0, 255] uint8 for display.\"\"\"\n    lo, hi = img.min(), img.max()\n    if hi - lo == 0:\n        return np.zeros_like(img, dtype=np.uint8)\n    return ((img - lo) / (hi - lo) * 255).astype(np.uint8)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 1. Aliasing\n",
    "\n",
    "When we downsample an image by simply skipping pixels, high-frequency content can **fold back** into the low-frequency range, creating false patterns called **aliasing artifacts** (Moiré patterns, jaggies).\n",
    "\n",
    "The fix: apply a **low-pass filter** (e.g., Gaussian blur) before downsampling to remove frequencies above the new Nyquist limit.\n",
    "\n",
    "$$\\sigma \\approx \\frac{\\text{factor}}{2}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.ndimage import gaussian_filter\n\n",
    "img_color = np.array(Image.open(IMAGE_PATH))\n",
    "img_gray = np.array(Image.open(GRAY_PATH))\n",
    "\n",
    "print(f\"Color \\u2014 shape: {img_color.shape}, dtype: {img_color.dtype}\")\n",
    "print(f\"Gray  \\u2014 shape: {img_gray.shape}, dtype: {img_gray.dtype}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Zone plate: aliasing in action\n",
    "\n",
    "A **zone plate** contains concentric circles with increasing frequency toward the edges — a perfect test for aliasing. When we naively downsample, the high-frequency rings produce false Moiré patterns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a zone plate (concentric circles with increasing frequency)\n",
    "size = 256\n",
    "x = np.linspace(-1, 1, size)\n",
    "xx, yy = np.meshgrid(x, x)\n",
    "zone_plate = (np.cos(80 * np.pi * (xx**2 + yy**2)) * 127.5 + 127.5).astype(np.uint8)\n",
    "\n",
    "# Naive downsample: just skip pixels\n",
    "factor = 4\n",
    "naive_down = zone_plate[::factor, ::factor]\n",
    "\n",
    "show_images(zone_plate, naive_down,\n",
    "            titles=[f\"Zone plate ({size}\\u00d7{size})\",\n",
    "                    f\"Naive \\u00d7{factor} downsample ({naive_down.shape[0]}\\u00d7{naive_down.shape[1]})\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Anti-aliased downsampling\n",
    "\n",
    "Apply a Gaussian blur **before** downsampling to remove high frequencies that would otherwise fold back."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "factor = 4\n",
    "sigma = factor / 2.0\n",
    "\n",
    "# Step 1: Low-pass filter\n",
    "blurred = gaussian_filter(img_gray.astype(np.float64), sigma=sigma)\n",
    "blurred = np.clip(blurred, 0, 255).astype(np.uint8)\n",
    "\n",
    "# Step 2: Downsample\n",
    "naive_down = img_gray[::factor, ::factor]\n",
    "aa_down = blurred[::factor, ::factor]\n",
    "\n",
    "show_images(img_gray, naive_down, aa_down,\n",
    "            titles=[\"Original\",\n",
    "                    f\"Naive \\u00d7{factor}\",\n",
    "                    f\"Anti-aliased \\u00d7{factor} (\\u03c3={sigma})\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "---\n## 2. Image Noise\n\nReal images are always contaminated by noise. The basic noise model:\n\n$$g(x,y) = f(x,y) + n(x,y)$$\n\nwhere $f$ is the clean image and $n$ is the noise. Two common types:\n- **Gaussian noise**: $n(x,y) \\sim N(0, \\sigma^2)$ — additive, affects every pixel a little bit\n- **Salt & Pepper noise**: random pixels flipped to 0 (pepper) or 255 (salt) — sparse but extreme"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gaussian noise\n",
    "\n",
    "Each pixel gets a small random perturbation drawn from a normal distribution. The parameter $\\sigma$ controls the noise intensity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_gaussian_noise(img, sigma):\n",
    "    \"\"\"Add Gaussian noise with standard deviation *sigma* to an image.\"\"\"\n",
    "    noise = np.random.normal(0, sigma, img.shape)\n",
    "    return np.clip(img.astype(np.float64) + noise, 0, 255).astype(np.uint8)\n",
    "\n",
    "np.random.seed(42)\n",
    "sigmas = [10, 25, 50]\n",
    "gauss_noisy = [add_gaussian_noise(img_gray, s) for s in sigmas]\n",
    "\n",
    "show_images(img_gray, *gauss_noisy,\n",
    "            titles=[\"Original\"] + [f\"\\u03c3 = {s}\" for s in sigmas])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Salt & Pepper noise\n",
    "\n",
    "Random pixels are set to the extreme values 0 or 255. The parameter controls the **density** (fraction of affected pixels)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_salt_pepper_noise(img, density):\n",
    "    \"\"\"Add salt & pepper noise with the given *density* (fraction of affected pixels).\"\"\"\n",
    "    noisy = img.copy()\n",
    "    mask = np.random.random(img.shape)\n",
    "    noisy[mask < density / 2] = 0        # pepper\n",
    "    noisy[mask > 1 - density / 2] = 255  # salt\n",
    "    return noisy\n",
    "\n",
    "np.random.seed(42)\n",
    "densities = [0.05, 0.10, 0.20]\n",
    "sp_noisy = [add_salt_pepper_noise(img_gray, d) for d in densities]\n",
    "\n",
    "show_images(img_gray, *sp_noisy,\n",
    "            titles=[\"Original\"] + [f\"Density = {d:.0%}\" for d in densities])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 3. Image Denoising\n",
    "\n",
    "Different noise types call for different filters:\n",
    "- **Gaussian noise** → Mean or Gaussian filter (averaging reduces variance)\n",
    "- **Salt & Pepper noise** → Median filter (outliers can never become the median)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mean and Gaussian filter for Gaussian noise\n",
    "\n",
    "Averaging $N$ independent noisy samples reduces variance by $N$:\n",
    "\n",
    "$$\\text{Var}(\\bar{n}) = \\frac{\\sigma^2}{N}$$\n",
    "\n",
    "A $5 \\times 5$ mean filter averages 25 pixels, reducing noise $\\sigma$ by a factor of $\\sqrt{25} = 5$.\n",
    "\n",
    "A Gaussian filter gives **higher weight to closer neighbors**, producing a smoother result than the box filter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.ndimage import uniform_filter, median_filter\n\n",
    "np.random.seed(42)\n",
    "noisy_gauss = add_gaussian_noise(img_gray, 25)\n",
    "\n",
    "denoised_mean = uniform_filter(noisy_gauss.astype(np.float64), size=5)\n",
    "denoised_mean = np.clip(denoised_mean, 0, 255).astype(np.uint8)\n",
    "\n",
    "denoised_gauss = gaussian_filter(noisy_gauss.astype(np.float64), sigma=1.5)\n",
    "denoised_gauss = np.clip(denoised_gauss, 0, 255).astype(np.uint8)\n",
    "\n",
    "show_images(img_gray, noisy_gauss, denoised_mean, denoised_gauss,\n",
    "            titles=[\"Original\", \"Noisy (\\u03c3=25)\", \"Mean 5\\u00d75\", \"Gaussian (\\u03c3=1.5)\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Median filter for Salt & Pepper noise\n",
    "\n",
    "The median filter sorts the neighborhood values and picks the **middle one**. Salt (255) or pepper (0) pixels are extreme outliers and can never become the median in a mostly-clean neighborhood.\n",
    "\n",
    "The median filter is **non-linear** — it is NOT a convolution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "noisy_sp = add_salt_pepper_noise(img_gray, 0.10)\n",
    "\n",
    "denoised_median = median_filter(noisy_sp, size=5)\n",
    "\n",
    "show_images(img_gray, noisy_sp, denoised_median,\n",
    "            titles=[\"Original\", \"S&P (10%)\", \"Median 5\\u00d75\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wrong tool: mean filter on Salt & Pepper\n",
    "\n",
    "What happens when we apply a **mean filter** to Salt & Pepper noise? Each salt pixel (255) gets **averaged** into its neighbors, spreading the extreme value into a gray blob instead of removing it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "noisy_sp = add_salt_pepper_noise(img_gray, 0.10)\n",
    "\n",
    "mean_on_sp = uniform_filter(noisy_sp.astype(np.float64), size=5)\n",
    "mean_on_sp = np.clip(mean_on_sp, 0, 255).astype(np.uint8)\n",
    "\n",
    "median_on_sp = median_filter(noisy_sp, size=5)\n",
    "\n",
    "show_images(noisy_sp, mean_on_sp, median_on_sp,\n",
    "            titles=[\"S&P (10%)\", \"Mean 5\\u00d75 (smears!)\", \"Median 5\\u00d75 (clean)\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 4. Quality Metrics\n",
    "\n",
    "How do we **quantify** how good a denoised image is? We need metrics that compare the result to the clean original.\n",
    "\n",
    "Three common metrics:\n",
    "- **MSE** (Mean Squared Error) — average squared pixel difference\n",
    "- **PSNR** (Peak Signal-to-Noise Ratio) — MSE on a log (dB) scale\n",
    "- **SSIM** (Structural Similarity) — perceptual quality based on local statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MSE and PSNR\n",
    "\n",
    "$$\\text{MSE} = \\frac{1}{HW}\\sum_{x,y}\\big[f(x,y) - \\hat{f}(x,y)\\big]^2$$\n",
    "\n",
    "$$\\text{PSNR} = 10 \\cdot \\log_{10}\\!\\left(\\frac{255^2}{\\text{MSE}}\\right) \\;\\text{dB}$$\n",
    "\n",
    "PSNR is just MSE on a logarithmic scale. **Higher is better.** Rule of thumb: >30 dB is good quality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.metrics import peak_signal_noise_ratio, structural_similarity\n\n",
    "np.random.seed(42)\n",
    "noisy_gauss = add_gaussian_noise(img_gray, 25)\n",
    "\n",
    "# Compute from scratch\n",
    "diff = img_gray.astype(np.float64) - noisy_gauss.astype(np.float64)\n",
    "mse = np.mean(diff ** 2)\n",
    "psnr_manual = 10 * np.log10(255**2 / mse)\n",
    "\n",
    "# Using skimage\n",
    "psnr_skimage = peak_signal_noise_ratio(img_gray, noisy_gauss)\n",
    "\n",
    "print(f\"MSE  = {mse:.2f}\")\n",
    "print(f\"PSNR (manual)  = {psnr_manual:.2f} dB\")\n",
    "print(f\"PSNR (skimage) = {psnr_skimage:.2f} dB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SSIM\n",
    "\n",
    "SSIM compares images using **local statistics** (mean, variance, covariance) within a sliding window. It captures luminance, contrast, and structural similarity separately.\n",
    "\n",
    "$$\\text{SSIM}(x,y) = \\frac{(2\\mu_x\\mu_y + C_1)(2\\sigma_{xy} + C_2)}{(\\mu_x^2 + \\mu_y^2 + C_1)(\\sigma_x^2 + \\sigma_y^2 + C_2)}$$\n",
    "\n",
    "- Range: $[0, 1]$, where 1 = identical\n",
    "- Closer to human perception than MSE/PSNR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "ssim_value = structural_similarity(img_gray, noisy_gauss)\nprint(f\"SSIM (global) = {ssim_value:.4f}\")\n\n# SSIM map: local SSIM at each pixel\n_, ssim_map = structural_similarity(img_gray, noisy_gauss, full=True)\n\nshow_images(img_gray, noisy_gauss,\n            titles=[\"Original\", f\"Noisy (PSNR={psnr_skimage:.1f} dB)\"])\nshow_maps(ssim_map, titles=[f\"SSIM map (mean={ssim_value:.3f})\"],\n          cmap=\"hot\", colorbar=True)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 4.1:** Apply a **Gaussian filter** ($\\sigma=1.0$) and a **Median filter** (size=3) to both `noisy_gauss` (Gaussian noise, $\\sigma=25$) and `noisy_sp` (Salt & Pepper, 10%).\n",
    "\n",
    "For each of the 4 combinations, compute the PSNR against the original image (`img_gray`). Display all four results using `show_denoising_comparison`. Which filter works best for which noise type?\n",
    "\n",
    "*Hint:* Use `gaussian_filter` and `median_filter` from scipy, and `peak_signal_noise_ratio` from skimage. The helper `show_denoising_comparison(img_gray, [result1, result2], [\"Title1\", \"Title2\"])` will display PSNR and SSIM automatically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input images\n",
    "np.random.seed(42)\n",
    "noisy_gauss = add_gaussian_noise(img_gray, 25)\n",
    "noisy_sp = add_salt_pepper_noise(img_gray, 0.10)\n",
    "show_images(noisy_gauss, noisy_sp,\n",
    "            titles=[\"noisy_gauss: Gaussian (σ=25)\", \"noisy_sp: S&P (10%)\"])\n",
    "\n",
    "# YOUR CODE HERE\n",
    "# Compute 4 denoised images:\n",
    "#   gauss_on_gauss  — Gaussian filter (σ=1.0) applied to noisy_gauss\n",
    "#   median_on_gauss — Median filter (size=3) applied to noisy_gauss\n",
    "#   gauss_on_sp     — Gaussian filter (σ=1.0) applied to noisy_sp\n",
    "#   median_on_sp    — Median filter (size=3) applied to noisy_sp\n",
    "\n",
    "\n",
    "print(\"=== Gaussian noise ===\")\n",
    "show_denoising_comparison(img_gray, [gauss_on_gauss, median_on_gauss],\n",
    "                          [\"Gaussian filter (σ=1.0)\", \"Median filter (3×3)\"])\n",
    "print(\"=== Salt & Pepper noise ===\")\n",
    "show_denoising_comparison(img_gray, [gauss_on_sp, median_on_sp],\n",
    "                          [\"Gaussian filter (σ=1.0)\", \"Median filter (3×3)\"])\n",
    "\n",
    "# Which filter works best for which noise type? Why?\n",
    "# (You may write your answer in Korean.)\n",
    "#\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 4.2:** Given `noisy_gauss` (Gaussian noise, $\\sigma=25$), sweep the Gaussian filter's $\\sigma$ across the values `[0.5, 1.0, 1.5, 2.0, 2.5, 3.0, 4.0, 5.0]`. For each $\\sigma$, denoise the image and compute PSNR.\n",
    "\n",
    "1. Plot $\\sigma$ vs PSNR (use `plt.plot`)\n",
    "2. Find the optimal $\\sigma$ (highest PSNR)\n",
    "3. Display three images: original (`img_gray`), noisy, and best-denoised\n",
    "\n",
    "*Hint:* Use `gaussian_filter(noisy.astype(np.float64), sigma=s)`, clip to [0, 255], and cast to uint8. The optimal $\\sigma$ is the one that maximizes PSNR."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input image\n",
    "np.random.seed(42)\n",
    "noisy_gauss = add_gaussian_noise(img_gray, 25)\n",
    "show_images(img_gray, noisy_gauss, titles=[\"Original (img_gray)\", \"Noisy (σ=25)\"])\n",
    "\n",
    "sigma_values = [0.5, 1.0, 1.5, 2.0, 2.5, 3.0, 4.0, 5.0]\n",
    "\n",
    "# YOUR CODE HERE\n",
    "# For each sigma in sigma_values, denoise and compute PSNR → store in psnr_values (list)\n",
    "# Find best_sigma (sigma with highest PSNR) and best_denoised (its denoised image)\n",
    "\n",
    "\n",
    "# Plot sigma vs PSNR\n",
    "plt.figure(figsize=(6, 4))\n",
    "plt.plot(sigma_values, psnr_values, \"o-\")\n",
    "plt.xlabel(\"Gaussian filter σ\")\n",
    "plt.ylabel(\"PSNR (dB)\")\n",
    "plt.title(\"Optimal Gaussian filter σ search\")\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Best σ = {best_sigma}, PSNR = {max(psnr_values):.2f} dB\")\n",
    "show_images(img_gray, noisy_gauss, best_denoised,\n",
    "            titles=[\"Original\", \"Noisy\", f\"Best denoised (σ={best_sigma})\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 5. Edge Detection\n",
    "\n",
    "An **edge** is a significant local change in intensity. We detect edges by computing **derivatives** of the image.\n",
    "\n",
    "The **gradient** at each pixel:\n",
    "\n",
    "$$\\nabla f = \\begin{bmatrix} G_x \\\\ G_y \\end{bmatrix} \\quad\\quad\n",
    "\\text{Magnitude: } |\\nabla f| = \\sqrt{G_x^2 + G_y^2} \\quad\\quad\n",
    "\\text{Direction: } \\theta = \\arctan\\!\\left(\\frac{G_y}{G_x}\\right)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1D derivative intuition\n",
    "\n",
    "Before working with 2D images, let's look at how derivatives detect edges in a 1D signal. The **first derivative** peaks at edges, while the **second derivative** crosses zero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "from scipy.ndimage import correlate\n\n# Extract a horizontal line from the image\nrow = 128\nprofile = img_gray[row, :].astype(np.float64)\n\n# 1st derivative (central difference)\nd1 = np.convolve(profile, [-1, 0, 1], mode=\"same\")\n\n# 2nd derivative\nd2 = np.convolve(profile, [1, -2, 1], mode=\"same\")\n\nshow_row_profile(img_gray, row, profile, d1, d2,\n                 titles=[f\"Grayscale image (red line = row {row})\",\n                         f\"1D profile (row {row})\",\n                         \"First derivative (peaks at edges)\",\n                         \"Second derivative (zero crossings at edges)\"],\n                 ylabels=[\"Intensity\", \"1st derivative\", \"2nd derivative\"],\n                 zero_line=True)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sobel operator (1st derivative)\n",
    "\n",
    "The Sobel operator computes the image gradient using two 3\\u00d73 kernels. Each kernel combines **smoothing** in one direction with a **derivative** in the other:\n",
    "\n",
    "$$G_x = \\begin{bmatrix}-1 & 0 & 1\\\\-2 & 0 & 2\\\\-1 & 0 & 1\\end{bmatrix} \\quad\\quad\n",
    "G_y = \\begin{bmatrix}-1 & -2 & -1\\\\0 & 0 & 0\\\\1 & 2 & 1\\end{bmatrix}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sobel_x = np.array([[-1, 0, 1],\n",
    "                     [-2, 0, 2],\n",
    "                     [-1, 0, 1]], dtype=np.float64)\n",
    "\n",
    "sobel_y = np.array([[-1, -2, -1],\n",
    "                     [ 0,  0,  0],\n",
    "                     [ 1,  2,  1]], dtype=np.float64)\n",
    "\n",
    "show_kernels(sobel_x, sobel_y, titles=[\"Sobel $G_x$\", \"Sobel $G_y$\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gx = correlate(img_gray.astype(np.float64), sobel_x, mode=\"constant\", cval=0)\n",
    "gy = correlate(img_gray.astype(np.float64), sobel_y, mode=\"constant\", cval=0)\n",
    "magnitude = np.sqrt(gx**2 + gy**2)\n",
    "\n",
    "show_images(img_gray, rescale_for_display(gx), rescale_for_display(gy), rescale_for_display(magnitude),\n",
    "            titles=[\"Original\", \"$G_x$ (horizontal edges)\", \"$G_y$ (vertical edges)\", \"Magnitude\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Laplacian (2nd derivative)\n",
    "\n",
    "The Laplacian computes the sum of second partial derivatives using a **single kernel**. Edges appear as **zero crossings**.\n",
    "\n",
    "$$\\nabla^2 f = \\frac{\\partial^2 f}{\\partial x^2} + \\frac{\\partial^2 f}{\\partial y^2}$$\n",
    "\n",
    "Two variants:\n",
    "- **4-connected**: $\\begin{bmatrix}0 & 1 & 0\\\\1 & -4 & 1\\\\0 & 1 & 0\\end{bmatrix}$ — horizontal & vertical\n",
    "- **8-connected**: $\\begin{bmatrix}1 & 1 & 1\\\\1 & -8 & 1\\\\1 & 1 & 1\\end{bmatrix}$ — includes diagonals (more isotropic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lap4 = np.array([[0,  1, 0],\n",
    "                  [1, -4, 1],\n",
    "                  [0,  1, 0]], dtype=np.float64)\n",
    "\n",
    "lap8 = np.array([[1,  1, 1],\n",
    "                  [1, -8, 1],\n",
    "                  [1,  1, 1]], dtype=np.float64)\n",
    "\n",
    "edges4 = correlate(img_gray.astype(np.float64), lap4, mode=\"constant\", cval=0)\n",
    "edges8 = correlate(img_gray.astype(np.float64), lap8, mode=\"constant\", cval=0)\n",
    "\n",
    "show_images(img_gray, rescale_for_display(edges4), rescale_for_display(edges8),\n",
    "            titles=[\"Original\", \"Laplacian (4-connected)\", \"Laplacian (8-connected)\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Laplacian of Gaussian (LoG)\n",
    "\n",
    "Raw derivatives amplify noise. The solution: **smooth first, then differentiate**. By linearity, we can combine these into a single kernel:\n",
    "\n",
    "$$\\nabla^2(G_\\sigma * f) = (\\nabla^2 G_\\sigma) * f$$\n",
    "\n",
    "The LoG kernel has a characteristic **Mexican hat** shape: a positive center surrounded by a negative ring."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_log_kernel(size, sigma):\n",
    "    \"\"\"Create a Laplacian of Gaussian (LoG) kernel.\"\"\"\n",
    "    k = size // 2\n",
    "    ax = np.arange(-k, k + 1, dtype=np.float64)\n",
    "    xx, yy = np.meshgrid(ax, ax)\n",
    "    r2 = xx**2 + yy**2\n",
    "    # LoG formula\n",
    "    kernel = -(1 / (np.pi * sigma**4)) * (1 - r2 / (2 * sigma**2)) * np.exp(-r2 / (2 * sigma**2))\n",
    "    kernel -= kernel.mean()  # ensure zero-sum\n",
    "    return kernel\n",
    "\n",
    "log_kernel = make_log_kernel(15, sigma=2.0)\n",
    "show_kernel_3d(log_kernel, title=\"LoG kernel (\\u03c3=2.0) \\u2014 Mexican hat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_edges = correlate(img_gray.astype(np.float64), log_kernel, mode=\"constant\", cval=0)\n",
    "\n",
    "show_images(img_gray, rescale_for_display(log_edges),\n",
    "            titles=[\"Original\", \"LoG edges (\\u03c3=2.0)\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Canny edge detection\n",
    "\n",
    "The Canny detector is a complete **pipeline** that produces clean, thin, connected edges:\n",
    "\n",
    "1. **Gaussian blur** — smooth the image (controlled by $\\sigma$)\n",
    "2. **Gradient computation** — Sobel for magnitude and direction\n",
    "3. **Non-maximum suppression** — keep only local maxima along the gradient direction → 1-pixel-thin edges\n",
    "4. **Hysteresis thresholding** — two thresholds ($T_\\text{high}$, $T_\\text{low}$) connect strong and weak edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "from skimage.feature import canny\n\n# Canny expects float image in [0, 1]\nimg_float = img_gray / 255.0\n\nedges_s1 = canny(img_float, sigma=1.0).astype(np.uint8) * 255\nedges_s2 = canny(img_float, sigma=2.0).astype(np.uint8) * 255\nedges_s4 = canny(img_float, sigma=4.0).astype(np.uint8) * 255\n\nshow_images(img_gray, edges_s1, edges_s2, edges_s4,\n            titles=[\"Original\", \"Canny \\u03c3=1.0\", \"Canny \\u03c3=2.0\", \"Canny \\u03c3=4.0\"])"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "**Exercise 5.1:** Apply the Sobel operator to the grayscale image (`img_gray`) to compute $G_x$ and $G_y$. Then compute:\n- **Gradient magnitude**: $|\\nabla f| = \\sqrt{G_x^2 + G_y^2}$\n- **Gradient direction**: $\\theta = \\text{arctan2}(G_y,\\, G_x)$\n\nDisplay the original and magnitude together, then display the direction map separately.\n\n*Hint:* Use `sobel_x`, `sobel_y` with `scipy.ndimage.correlate`. For direction, use `np.arctan2(gy, gx)`. Display the magnitude with `rescale_for_display` and the direction with `show_maps` using `cmap='hsv'` (angles map naturally to a circular colormap)."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Input image\nshow_images(img_gray, titles=[\"img_gray\"])\n\n# YOUR CODE HERE\n# 1. gx = correlate(img_gray, sobel_x, ...)\n# 2. gy = correlate(img_gray, sobel_y, ...)\n# 3. magnitude = sqrt(gx² + gy²)\n# 4. direction = arctan2(gy, gx)\n\n\nshow_images(img_gray, rescale_for_display(magnitude),\n            titles=[\"Original\", \"Gradient magnitude\"])\nshow_maps(direction, titles=[\"Gradient direction (θ)\"], cmap=\"hsv\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 5.2:** A noisy version of `img_gray` (Gaussian noise, σ=30) is prepared as `noisy` below.\n",
    "Apply four edge detectors to `noisy` and display the results:\n",
    "\n",
    "1. **Sobel** magnitude ($\\sqrt{G_x^2 + G_y^2}$)\n",
    "2. **Laplacian** (4-connected kernel `lap4`)\n",
    "3. **LoG** (use `make_log_kernel(15, 2.0)`)\n",
    "4. **Canny** (`canny(img / 255.0, sigma=2.0)`)\n",
    "\n",
    "Which operators handle noise well, and which ones break down? Why?\n",
    "\n",
    "*Hint:* Use the Sobel/Laplacian/LoG patterns from the demos above, and `rescale_for_display` for Sobel/Laplacian/LoG results. Canny returns a boolean array — multiply by 255 for display.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input image\n",
    "np.random.seed(42)\n",
    "noisy = add_gaussian_noise(img_gray, 30)\n",
    "show_images(img_gray, noisy, titles=[\"img_gray\", \"noisy (σ=30)\"])\n",
    "\n",
    "# YOUR CODE HERE\n",
    "# Apply 4 edge detectors to noisy:\n",
    "#   sobel_result  — Sobel magnitude (sqrt of gx² + gy²)\n",
    "#   lap_result    — Laplacian with lap4 kernel\n",
    "#   log_result    — LoG with make_log_kernel(15, 2.0)\n",
    "#   canny_result  — canny(noisy / 255.0, sigma=2.0) * 255\n",
    "\n",
    "\n",
    "show_images(rescale_for_display(sobel_result), rescale_for_display(lap_result),\n",
    "            rescale_for_display(log_result), canny_result,\n",
    "            titles=[\"Sobel\", \"Laplacian\", \"LoG (σ=2)\", \"Canny (σ=2)\"])\n",
    "\n",
    "# Which operators handle noise well? Why?\n",
    "# (You may write your answer in Korean.)\n",
    "#\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "---\n## Final Challenge\n\n### Bilateral Filter: Edge-Preserving Denoising\n\nAll the filters we have used so far (mean, Gaussian, median) share a common limitation: they smooth **everything**, including edges. The Gaussian filter, for example, reduces noise but also blurs sharp boundaries.\n\nThe **bilateral filter** solves this by using two Gaussian weights:\n- **Spatial weight** $G_{\\sigma_s}(\\|p - q\\|)$ — nearby pixels contribute more (same as Gaussian filter)\n- **Range weight** $G_{\\sigma_r}(|I_p - I_q|)$ — pixels with **similar intensity** contribute more\n\n$$\\text{BF}[I]_p = \\frac{1}{W_p}\\sum_{q \\in N(p)} G_{\\sigma_s}(\\|p-q\\|)\\;\\cdot\\;G_{\\sigma_r}(|I_p - I_q|)\\;\\cdot\\;I_q$$\n\nwhere $W_p = \\sum_q G_{\\sigma_s} \\cdot G_{\\sigma_r}$ is a normalization factor.\n\n**Key insight**: At an edge, pixels on the opposite side have very different intensity, so their range weight becomes near-zero. The filter effectively **stops at edges** while still averaging similar pixels.\n\nThe figure below (from Durand & Dorsey, 2002) illustrates the bilateral filtering process for a single pixel:"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "show_figure(Image.open(BF_FIG_PATH),\n            title=\"Bilateral filtering: input → spatial kernel → range kernel → combined weight → output\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your task:** Complete the `bilateral_filter` function below. The outer loop, padding, and spatial weight precomputation are provided. You need to fill in the **4 lines** inside the loop:\n",
    "\n",
    "1. Compute **range weights**: apply a Gaussian to the intensity difference between each neighbor and the center pixel\n",
    "2. Combine spatial and range weights\n",
    "3. Normalize so the weights sum to 1\n",
    "4. Compute the weighted average\n",
    "\n",
    "Then apply your bilateral filter to a noisy image and compare with a standard Gaussian filter using PSNR.\n",
    "\n",
    "*Hint:* The range weight for each neighbor is $\\exp\\!\\left(-\\frac{(I_\\text{neighbor} - I_\\text{center})^2}{2\\sigma_r^2}\\right)$. You can compute this for the entire neighborhood array at once using NumPy broadcasting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bilateral_filter(img, d=5, sigma_s=2.0, sigma_r=25.0):\n",
    "    \"\"\"Bilateral filter: edge-preserving denoising.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    img     : 2D uint8 array (grayscale image)\n",
    "    d       : kernel diameter (must be odd)\n",
    "    sigma_s : spatial Gaussian standard deviation\n",
    "    sigma_r : range (intensity) Gaussian standard deviation\n",
    "    \"\"\"\n",
    "    img_f = img.astype(np.float64)\n",
    "    h, w = img_f.shape\n",
    "    r = d // 2\n",
    "    output = np.zeros_like(img_f)\n",
    "\n",
    "    # Pre-compute spatial Gaussian weights (same for every pixel)\n",
    "    ax = np.arange(-r, r + 1, dtype=np.float64)\n",
    "    xx, yy = np.meshgrid(ax, ax)\n",
    "    spatial_weights = np.exp(-(xx**2 + yy**2) / (2 * sigma_s**2))\n",
    "\n",
    "    # Pad image for border handling\n",
    "    padded = np.pad(img_f, r, mode=\"reflect\")\n",
    "\n",
    "    for i in range(h):\n",
    "        for j in range(w):\n",
    "            # Extract the local neighborhood\n",
    "            neighborhood = padded[i : i + d, j : j + d]\n",
    "            center_val = img_f[i, j]\n",
    "\n",
    "            # YOUR CODE HERE\n",
    "            # 1. range_weights = Gaussian of (neighborhood - center_val)\n",
    "            # 2. combined_weights = spatial_weights * range_weights\n",
    "            # 3. Normalize combined_weights so they sum to 1\n",
    "            # 4. output[i, j] = weighted sum of neighborhood\n",
    "\n",
    "    return np.clip(output, 0, 255).astype(np.uint8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test your implementation and compare with a standard Gaussian filter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input image\n",
    "np.random.seed(42)\n",
    "noisy = add_gaussian_noise(img_gray, 25)\n",
    "show_images(img_gray, noisy, titles=[\"Original (img_gray)\", \"Noisy (σ=25)\"])\n",
    "\n",
    "# YOUR CODE HERE\n",
    "# 1. bf_result = bilateral_filter(noisy, d=5, sigma_s=2.0, sigma_r=25.0)\n",
    "# 2. gauss_result — apply gaussian_filter(noisy, sigma=1.0) for comparison\n",
    "\n",
    "\n",
    "show_denoising_comparison(img_gray, [noisy, gauss_result, bf_result],\n",
    "                          [\"Noisy\", \"Gaussian filter\", \"Bilateral filter\"])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}