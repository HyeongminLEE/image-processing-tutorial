{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 2: Image Processing Basics — Lab Practice\n",
    "\n",
    "**Topics:** Pixels, Point Processing & Histograms\n",
    "\n",
    "This notebook accompanies the Week 2 lecture slides. We will load images as NumPy arrays, perform point processing operations, compute histograms, and explore color spaces — all hands-on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from matplotlib.colors import rgb_to_hsv, hsv_to_rgb\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Environment setup\n",
    "\n",
    "This notebook works both **locally** and on **Google Colab**.\n",
    "- **Local**: images are loaded from the repository's `images/` folder.\n",
    "- **Colab**: images are automatically downloaded from GitHub on first run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, urllib.request\n",
    "\n",
    "# Detect Google Colab\n",
    "IN_COLAB = \"google.colab\" in str(get_ipython()) if hasattr(__builtins__, \"__IPYTHON__\") else False\n",
    "\n",
    "# Image paths\n",
    "REPO_URL = \"https://raw.githubusercontent.com/HyeongminLEE/image-processing-tutorial/main\"\n",
    "IMAGE_DIR = \"images\"\n",
    "IMAGE_NAME = \"parrots_square.jpg\"\n",
    "\n",
    "if IN_COLAB:\n",
    "    os.makedirs(IMAGE_DIR, exist_ok=True)\n",
    "    url = f\"{REPO_URL}/{IMAGE_DIR}/{IMAGE_NAME}\"\n",
    "    dest = os.path.join(IMAGE_DIR, IMAGE_NAME)\n",
    "    if not os.path.exists(dest):\n",
    "        print(f\"Downloading {IMAGE_NAME} ...\")\n",
    "        urllib.request.urlretrieve(url, dest)\n",
    "        print(\"Done.\")\n",
    "    IMAGE_PATH = dest\n",
    "else:\n",
    "    IMAGE_PATH = os.path.join(\"..\", IMAGE_DIR, IMAGE_NAME)\n",
    "\n",
    "GRAY_PATH = \"parrots_gray.jpg\"\n",
    "\n",
    "print(f\"Image path: {IMAGE_PATH}\")\n",
    "print(f\"Running on: {'Google Colab' if IN_COLAB else 'Local'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display helpers\n",
    "\n",
    "We define two utility functions used throughout this notebook so that visualization code stays minimal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_images(*imgs, titles=None, scale=4):\n",
    "    \"\"\"Display images in a single row.\n",
    "\n",
    "    Grayscale (2-D uint8) arrays automatically use a gray colormap.\n",
    "    *titles* is an optional list of strings, one per image.\n",
    "    \"\"\"\n",
    "    n = len(imgs)\n",
    "    fig, axes = plt.subplots(1, n, figsize=(scale * n, scale))\n",
    "    if n == 1:\n",
    "        axes = [axes]\n",
    "    for i, (ax, img) in enumerate(zip(axes, imgs)):\n",
    "        if img.ndim == 2:\n",
    "            ax.imshow(img, cmap=\"gray\", vmin=0, vmax=255)\n",
    "        else:\n",
    "            ax.imshow(img)\n",
    "        if titles:\n",
    "            ax.set_title(titles[i])\n",
    "        ax.axis(\"off\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def show_with_hist(*imgs, titles=None, scale=4):\n",
    "    \"\"\"Display grayscale images (top row) with their histograms (bottom row).\"\"\"\n",
    "    n = len(imgs)\n",
    "    fig, axes = plt.subplots(2, n, figsize=(scale * n, scale * 1.5))\n",
    "    if n == 1:\n",
    "        axes = axes.reshape(2, 1)\n",
    "    for i, img in enumerate(imgs):\n",
    "        axes[0, i].imshow(img, cmap=\"gray\", vmin=0, vmax=255)\n",
    "        if titles:\n",
    "            axes[0, i].set_title(titles[i])\n",
    "        axes[0, i].axis(\"off\")\n",
    "        h, _ = np.histogram(img.ravel(), 256, [0, 256])\n",
    "        axes[1, i].fill_between(np.arange(256), h, alpha=0.7)\n",
    "        axes[1, i].set_xlim([0, 255])\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 0. NumPy Crash Course\n",
    "\n",
    "Images in Python are just **NumPy arrays**. Before touching any pixels, let's get comfortable with the array operations we'll use throughout this course: creating, slicing, reshaping, flipping, and combining arrays."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From a Python list\n",
    "a = np.array([1, 2, 3, 4, 5])\n",
    "print(\"a       =\", a)\n",
    "print(\"a.shape =\", a.shape)      # (5,)  — 1-D, 5 elements\n",
    "print(\"a.ndim  =\", a.ndim)       # 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2-D array (matrix)\n",
    "b = np.array([[1, 2, 3],\n",
    "              [4, 5, 6]])\n",
    "print(\"b.shape =\", b.shape)         # (2, 3) — 2 rows, 3 columns\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Handy constructors\nprint(\"zeros:\\n\", np.zeros((2, 3)))                  # all 0s\nprint(\"ones:\\n\", np.ones((2, 3)))                    # all 1s\nprint(\"arange  :\", np.arange(0, 10, 2))              # [0, 2, 4, 6, 8]  (start, stop, step)\nprint(\"linspace:\", np.linspace(0, 1, 5))             # 5 evenly spaced values in [0, 1]\n\n# Create arrays that match the shape of an existing array\nref = np.array([[1, 2], [3, 4]])\nprint(\"zeros_like:\\n\", np.zeros_like(ref))           # same shape, all 0\nprint(\"ones_like:\\n\", np.ones_like(ref))             # same shape, all 1\nprint(\"copy:\\n\", ref.copy())                         # independent deep copy"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Indexing & slicing\n",
    "\n",
    "Works like Python lists, but extended to multiple dimensions with **comma-separated indices**: `array[row, col]`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "m = np.arange(12).reshape(3, 4)   # 3×4 matrix  [0..11]\nprint(m)\nprint()\n\nprint(\"m[0, 2]      =\", m[0, 2])        # single element: row 0, col 2\nprint(\"m[1]         =\", m[1])            # entire row 1\nprint(\"m[:, 0]      =\", m[:, 0])         # entire column 0  (: means 'all rows')\nprint(f\"m[0:2, 1:3]  =\\n{m[0:2, 1:3]}\")  # sub-matrix: rows 0-1, cols 1-2"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Negative indexing & reversing\nprint(\"last row      =\", m[-1])           # last row\nprint(f\"rows reversed =\\n{m[::-1]}\")       # reverse row order → vertical flip\nprint(f\"cols reversed =\\n{m[:, ::-1]}\")    # reverse column order → horizontal flip"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Element-wise arithmetic\n",
    "\n",
    "Operators `+`, `-`, `*`, `/`, `**` work **element-by-element**. A scalar is automatically **broadcast** to match the array shape."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v = np.array([10, 20, 30])\n",
    "\n",
    "print(\"v + 5   =\", v + 5)           # scalar broadcast: [15, 25, 35]\n",
    "print(\"v * 2   =\", v * 2)           # [20, 40, 60]\n",
    "print(\"v ** 2  =\", v ** 2)          # [100, 400, 900]\n",
    "print(\"v > 15  =\", v > 15)          # boolean array: [False, True, True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Two arrays of the same shape → element-wise\n",
    "w = np.array([1, 2, 3])\n",
    "print(\"v + w =\", v + w)             # [11, 22, 33]\n",
    "print(\"v * w =\", v * w)             # [10, 40, 90]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reshape, ravel, flatten\n",
    "\n",
    "These change the **logical shape** of an array without changing its data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "a = np.arange(12)\nprint(\"1-D      =\", a)              # [0, 1, ..., 11]   shape (12,)\n\nb = a.reshape(3, 4)                  # → shape (3, 4)\nprint(f\"reshaped =\\n{b}\")\n\nprint(\"ravel    =\", b.ravel())       # back to 1-D  (view — shares memory)\nprint(\"flatten  =\", b.flatten())     # back to 1-D  (always a new copy)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding / removing dimensions: expand_dims & squeeze\n",
    "\n",
    "These are important when working with images:\n",
    "- A grayscale image has shape `(H, W)` — but some functions expect `(H, W, 1)`.\n",
    "- `np.expand_dims(arr, axis)` inserts a **new axis of size 1** at the given position.\n",
    "- `np.squeeze(arr)` removes **all axes of size 1**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.zeros((4, 5))               # shape (4, 5)\n",
    "print(\"original shape   :\", a.shape)\n",
    "\n",
    "# expand_dims — add a dimension\n",
    "b = np.expand_dims(a, axis=2)       # (4, 5) → (4, 5, 1)\n",
    "print(\"expand axis=2    :\", b.shape)\n",
    "\n",
    "c = np.expand_dims(a, axis=0)       # (4, 5) → (1, 4, 5)\n",
    "print(\"expand axis=0    :\", c.shape)\n",
    "\n",
    "# Shorthand: index with None (same as np.newaxis)\n",
    "d = a[:, :, None]                   # (4, 5) → (4, 5, 1)\n",
    "print(\"[:, :, None]     :\", d.shape)\n",
    "\n",
    "e = a[None, :, :]                   # (4, 5) → (1, 4, 5)\n",
    "print(\"[None, :, :]     :\", e.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# squeeze — remove all size-1 dimensions\n",
    "f = np.zeros((1, 4, 5, 1))\n",
    "print(\"before squeeze:\", f.shape)    # (1, 4, 5, 1)\n",
    "print(\"after  squeeze:\", np.squeeze(f).shape)  # (4, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Concatenate & stack\n",
    "\n",
    "- `np.concatenate` joins arrays along an **existing** axis.\n",
    "- `np.stack` joins arrays along a **new** axis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = np.ones((2, 3))\n",
    "q = np.zeros((2, 3))\n",
    "\n",
    "# concatenate along axis 0 (stack rows)\n",
    "r = np.concatenate([p, q], axis=0)\n",
    "print(\"concat axis=0 :\", r.shape)   # (4, 3)\n",
    "print(r)\n",
    "print()\n",
    "\n",
    "# concatenate along axis 1 (append columns)\n",
    "s = np.concatenate([p, q], axis=1)\n",
    "print(\"concat axis=1 :\", s.shape)   # (2, 6)\n",
    "print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stack — adds a NEW axis\n",
    "t = np.stack([p, q], axis=0)\n",
    "print(\"stack axis=0 :\", t.shape)    # (2, 2, 3) — two (2,3) arrays into a new dim\n",
    "\n",
    "u = np.stack([p, q], axis=2)\n",
    "print(\"stack axis=2 :\", u.shape)    # (2, 3, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A common image use-case: build an RGB image from three single-channel arrays.\n",
    "\n",
    "```python\n",
    "rgb = np.stack([r_channel, g_channel, b_channel], axis=2)  # (H, W, 3)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### Exercises\n\n**Exercise 0.1:** Create a 1-D array of integers from 0 to 255 (use `np.arange`), then reshape it to `(16, 16)` and print its shape.\nNext, slice out the **center 8×8 block** (rows 4–11, cols 4–11) and compute its mean with `.mean()`."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "**Exercise 0.2:** Given `a = np.arange(4)` (shape `(4,)`) and `b = np.arange(3)` (shape `(3,)`),\ncompute the **outer product** — a `(4, 3)` matrix where element `[i, j] = a[i] * b[j]`.\n\n*Hint:* Use `None` indexing to make their shapes broadcastable: reshape `a` to `(4, 1)` and keep `b` as `(3,)`, then multiply."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 1. Loading and Exploring Images\n",
    "\n",
    "We use **PIL** (`Pillow`) to open image files and immediately convert them to NumPy arrays. This gives us full control through array indexing and arithmetic.\n",
    "\n",
    "Key functions:\n",
    "- `Image.open(path)` — returns a PIL Image object\n",
    "- `np.array(pil_img)` — converts it to a NumPy ndarray\n",
    "- `.shape`, `.dtype`, `.min()`, `.max()` — basic array inspection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_color = np.array(Image.open(IMAGE_PATH))\n",
    "\n",
    "print(f\"Shape : {img_color.shape}\")   # (H, W, C)\n",
    "print(f\"Dtype : {img_color.dtype}\")   # uint8\n",
    "print(f\"Min   : {img_color.min()}\")\n",
    "print(f\"Max   : {img_color.max()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_images(img_color, titles=[\"Color image (RGB)\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating and saving a grayscale version\n",
    "\n",
    "`Image.convert('L')` uses the ITU-R 601-2 luma formula:\n",
    "\n",
    "$$L = 0.299 R + 0.587 G + 0.114 B$$\n",
    "\n",
    "We save it to disk so we can load it directly in later sections."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_gray = np.array(Image.open(IMAGE_PATH).convert(\"L\"))\n",
    "\n",
    "print(f\"Shape : {img_gray.shape}\")   # (H, W) — no channel dimension\n",
    "print(f\"Dtype : {img_gray.dtype}\")\n",
    "\n",
    "# Save for later use\n",
    "Image.fromarray(img_gray).save(GRAY_PATH)\n",
    "print(f\"Saved grayscale image to {GRAY_PATH}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_images(img_gray, titles=[\"Grayscale image\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accessing individual pixels\n",
    "\n",
    "- Color pixel → a 1D array of 3 values `[R, G, B]`\n",
    "- Grayscale pixel → a single scalar value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "row, col = 100, 200\n",
    "\n",
    "print(f\"Color pixel at ({row}, {col}): {img_color[row, col]}\")\n",
    "print(f\"Gray  pixel at ({row}, {col}): {img_gray[row, col]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 2. Channel Extraction\n",
    "\n",
    "An RGB image has 3 channels stored along axis 2. We can slice them out individually.\n",
    "\n",
    "When displaying a single channel with `imshow`, use `cmap='gray'` — otherwise matplotlib applies a colormap that can be misleading."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_channel = img_color[:, :, 0]\n",
    "g_channel = img_color[:, :, 1]\n",
    "b_channel = img_color[:, :, 2]\n",
    "\n",
    "show_images(img_color, r_channel, g_channel, b_channel,\n",
    "            titles=[\"Original\", \"Red channel\", \"Green channel\", \"Blue channel\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### Exercises\n\n**Exercise 2.1:** Create three *color* images that isolate each channel:\n- **Red-only**: keep the R channel, set G and B to 0\n- **Green-only**: keep G, set R and B to 0\n- **Blue-only**: keep B, set R and G to 0\n\nDisplay all four (original + 3 filtered) in a row using `show_images`.\n\n*Hint:* Start with `np.zeros_like(img_color)` to get a black image of the same shape, then copy one channel into it: `red_only[:, :, 0] = img_color[:, :, 0]`."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 3. Flip, Rotate, and Crop\n",
    "\n",
    "NumPy slicing gives us geometric transforms for free:\n",
    "\n",
    "| Operation | Code |\n",
    "|---|---|\n",
    "| Vertical flip | `img[::-1]` |\n",
    "| Horizontal flip | `img[:, ::-1]` |\n",
    "| 90° rotation | `np.rot90(img)` |\n",
    "| Crop | `img[y1:y2, x1:x2]` |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_images(img_color, img_color[:, ::-1], img_color[::-1], np.rot90(img_color),\n",
    "            titles=[\"Original\", \"H-flip\", \"V-flip\", \"Rot 90°\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cropping\n",
    "\n",
    "Remember the coordinate order: `img[row_start:row_end, col_start:col_end]`, i.e., **y first, x second**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "H, W = img_color.shape[:2]\n",
    "cropped = img_color[H//4 : 3*H//4, W//4 : 3*W//4]\n",
    "\n",
    "show_images(img_color, cropped,\n",
    "            titles=[f\"Original ({H}×{W})\", f\"Center crop ({cropped.shape[0]}×{cropped.shape[1]})\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### Exercises\n\n**Exercise 3.1:** Rotate the image by 180° using **only slicing** (do not use `np.rot90`).\n\n*Hint:* A 180° rotation is the same as flipping both vertically and horizontally."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 3.2:** Crop a region of your choice, then create a 1×2 figure showing the crop and its horizontally-flipped version."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 4. Point Processing: Arithmetic Operations\n",
    "\n",
    "Point processing transforms each pixel **independently**: $g(x,y) = T[f(x,y)]$.\n",
    "\n",
    "The simplest transforms are arithmetic: add, subtract, multiply.\n",
    "\n",
    "> **Critical:** Images are stored as `uint8` (0–255). Arithmetic can overflow or underflow. Always **cast to a wider type first**, then **clip** back to [0, 255]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gray = np.array(Image.open(GRAY_PATH))\n",
    "print(f\"Shape: {gray.shape}, dtype: {gray.dtype}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Brightness: Add / Subtract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bright = np.clip(gray.astype(np.int16) + 80, 0, 255).astype(np.uint8)\n",
    "dark   = np.clip(gray.astype(np.int16) - 80, 0, 255).astype(np.uint8)\n",
    "\n",
    "show_images(dark, gray, bright, titles=[\"Darker (−80)\", \"Original\", \"Brighter (+80)\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Contrast: Multiply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "high_contrast = np.clip(gray.astype(np.float64) * 2.0, 0, 255).astype(np.uint8)\n",
    "low_contrast  = (gray.astype(np.float64) * 0.5).astype(np.uint8)\n",
    "\n",
    "show_images(low_contrast, gray, high_contrast,\n",
    "            titles=[\"×0.5 (low contrast)\", \"Original\", \"×2.0 (high contrast)\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Complement / Negative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "negative = 255 - gray  # uint8 subtraction is safe here since 255 >= any pixel\n",
    "\n",
    "show_images(gray, negative, titles=[\"Original\", \"Negative (255 − f)\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Why casting matters: uint8 overflow demo\n",
    "\n",
    "`uint8` arithmetic **wraps around** modulo 256. For example, `200 + 100 = 44` (not 300). This produces garbage results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bad_result  = gray + np.uint8(200)                                       # WRONG: uint8 overflow\n",
    "good_result = np.clip(gray.astype(np.int16) + 200, 0, 255).astype(np.uint8)  # CORRECT\n",
    "\n",
    "show_images(gray, bad_result, good_result,\n",
    "            titles=[\"Original\", \"uint8 overflow (WRONG)\", \"With clipping (CORRECT)\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing transfer functions\n",
    "\n",
    "A transfer function maps each input intensity to an output intensity. We can plot them on a 256×256 grid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.arange(256)\n",
    "\n",
    "plt.figure(figsize=(5, 5))\n",
    "plt.plot(x, x, \"k--\", label=\"Identity\")\n",
    "plt.plot(x, np.clip(x + 80, 0, 255), label=\"+80\")\n",
    "plt.plot(x, np.clip(x - 80, 0, 255), label=\"−80\")\n",
    "plt.plot(x, np.clip(x * 2, 0, 255), label=\"×2\")\n",
    "plt.plot(x, (x * 0.5).astype(int), label=\"×0.5\")\n",
    "plt.xlabel(\"Input intensity\")\n",
    "plt.ylabel(\"Output intensity\")\n",
    "plt.title(\"Transfer functions\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### Exercises\n\n**Exercise 4.1:** Create a \"high-contrast negative\" of the grayscale image in two steps:\n1. Invert it: `negative = 255 - gray`\n2. Multiply by 1.5 to boost contrast (don't forget to cast, clip, and cast back)\n\nDisplay the original and the result side by side."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "**Exercise 4.2:** Apply brightness adjustment (+60) to the **color** image (all three channels). Remember to cast to `int16` before adding, then clip back to `[0, 255]` and convert to `uint8`. Display before and after with `show_images`."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 5. Gamma Correction\n",
    "\n",
    "Gamma correction applies a **power-law** transform:\n",
    "\n",
    "$$g = 255 \\left(\\frac{f}{255}\\right)^\\gamma$$\n",
    "\n",
    "- $\\gamma < 1$: brightens dark regions (expands shadows)\n",
    "- $\\gamma = 1$: identity (no change)\n",
    "- $\\gamma > 1$: darkens the image (compresses shadows)\n",
    "\n",
    "We normalize to [0, 1], apply the power, then scale back to [0, 255]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.arange(256)\n",
    "\n",
    "plt.figure(figsize=(5, 5))\n",
    "plt.plot(x, x, \"k--\", label=\"γ = 1.0 (identity)\")\n",
    "for gamma in [0.3, 0.5, 2.0, 3.0]:\n",
    "    plt.plot(x, 255 * (x / 255.0) ** gamma, label=f\"γ = {gamma}\")\n",
    "plt.xlabel(\"Input\")\n",
    "plt.ylabel(\"Output\")\n",
    "plt.title(\"Gamma curves\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_gamma(img, gamma):\n",
    "    \"\"\"Apply gamma correction to a uint8 image (grayscale or color).\"\"\"\n",
    "    return (255 * (img / 255.0) ** gamma).astype(np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_images(apply_gamma(gray, 0.4), gray, apply_gamma(gray, 2.5),\n",
    "            titles=[\"γ = 0.4 (brighten)\", \"Original\", \"γ = 2.5 (darken)\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gamma on a color image\n",
    "\n",
    "The same function works element-wise on all three channels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_images(apply_gamma(img_color, 0.4), img_color, apply_gamma(img_color, 2.5),\n",
    "            titles=[\"γ = 0.4\", \"Original\", \"γ = 2.5\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### Exercises\n\n**Exercise 5.1:** Apply 5 different gamma values (0.2, 0.5, 1.0, 2.0, 5.0) to the grayscale image using the `apply_gamma` function defined above. Display all 5 results in a single row with `show_images`, using the gamma value as each title (e.g., `\"γ = 0.2\"`)."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 6. Lookup Tables (LUT)\n",
    "\n",
    "Any point transform $T: [0,255] \\to [0,255]$ can be stored as an array of 256 entries. Applying it to an image is then a single **fancy-indexing** operation:\n",
    "\n",
    "```python\n",
    "T = np.array([...])  # shape (256,), dtype uint8\n",
    "result = T[img]       # each pixel used as an index\n",
    "```\n",
    "\n",
    "This is extremely fast because there are no per-pixel arithmetic operations at runtime — just table lookups."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Threshold LUT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "T_thresh = np.zeros(256, dtype=np.uint8)\n",
    "T_thresh[128:] = 255\n",
    "\n",
    "show_images(gray, T_thresh[gray], titles=[\"Original\", \"Threshold at 128\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### More LUT examples: Solarize & Posterize\n",
    "\n",
    "- **Solarize**: Invert pixels above a threshold → creates an \"X\" shaped transfer function\n",
    "- **Posterize** (4 levels): Quantize 256 grey levels into just 4 steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.arange(256)\n",
    "\n",
    "# Solarize: invert pixels above 128\n",
    "T_solar = x.copy().astype(np.uint8)\n",
    "T_solar[128:] = 255 - T_solar[128:]\n",
    "\n",
    "# Posterize: 4 levels (0, 85, 170, 255)\n",
    "T_poster = np.zeros(256, dtype=np.uint8)\n",
    "T_poster[0:64]    = 0\n",
    "T_poster[64:128]  = 85\n",
    "T_poster[128:192] = 170\n",
    "T_poster[192:256] = 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_images(T_thresh[gray], T_solar[gray], T_poster[gray],\n",
    "            titles=[\"Threshold\", \"Solarize\", \"Posterize (4 levels)\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also visualize the transfer functions (LUTs) themselves as line plots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 3, figsize=(12, 3))\n",
    "for ax, lut, name in zip(axes, [T_thresh, T_solar, T_poster],\n",
    "                          [\"Threshold\", \"Solarize\", \"Posterize\"]):\n",
    "    ax.plot(x, lut)\n",
    "    ax.plot(x, x, \"k--\", alpha=0.3)\n",
    "    ax.set_title(name)\n",
    "    ax.set_xlabel(\"Input\")\n",
    "    ax.set_ylabel(\"Output\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gamma as a LUT\n",
    "\n",
    "Any formula-based transform can also be pre-computed as a LUT. This is especially useful when applying the same transform to many images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "gamma_val = 0.4\nT_gamma = (255 * (np.arange(256) / 255.0) ** gamma_val).astype(np.uint8)\n\nlut_result    = T_gamma[gray]\ndirect_result = apply_gamma(gray, gamma_val)\n\nshow_images(lut_result, direct_result, titles=[\"Gamma via LUT\", \"Gamma via formula\"])"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### Exercises\n\n**Exercise 6.1:** Build a custom **piecewise LUT** (a 256-element array `T`) with these rules:\n- Input 0–63 → Output 0 (everything dark stays black)\n- Input 64–191 → Output linearly increases from 0 to 255\n- Input 192–255 → Output 255 (everything bright stays white)\n\nThen:\n1. Plot the transfer function: `plt.plot(np.arange(256), T)`\n2. Apply it to the grayscale image with `T[gray]` and display the result\n\n*Hint:* `np.linspace(0, 255, 128).astype(np.uint8)` gives 128 evenly spaced values from 0 to 255 — use this for the middle section."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "**Exercise 6.2:** Create a \"warm tone\" effect on the **color** image by applying a different gamma LUT to each channel:\n- **Red**: gamma 0.8 (slightly brighter → warmer)\n- **Green**: identity (no change)\n- **Blue**: gamma 1.3 (slightly darker → less cool)\n\nBuild each LUT as a 256-element array, then apply them channel by channel:\n```python\nresult[:, :, 0] = T_red[img_color[:, :, 0]]\n```\nDisplay before and after with `show_images`."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 7. Histograms\n",
    "\n",
    "A histogram counts how many pixels have each intensity value (0–255). It reveals the **contrast characteristics** of an image at a glance.\n",
    "\n",
    "Key function: `np.histogram(img.ravel(), bins=256, range=[0, 256])`\n",
    "\n",
    "- `.ravel()` flattens the image to 1D (required by `np.histogram`)\n",
    "- `bins=256` gives one bin per grey level\n",
    "- Returns `(hist, bin_edges)` — we typically ignore `bin_edges`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist, bins = np.histogram(gray.ravel(), 256, [0, 256])\n",
    "\n",
    "plt.figure(figsize=(8, 3))\n",
    "plt.fill_between(np.arange(256), hist, alpha=0.7)\n",
    "plt.xlabel(\"Pixel intensity\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.title(\"Histogram of grayscale image\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Histogram shapes tell a story\n",
    "\n",
    "Let's create dark, bright, and low-contrast versions and compare their histograms using `show_with_hist`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dark_img   = np.clip(gray.astype(np.float64) * 0.4, 0, 255).astype(np.uint8)\n",
    "bright_img = np.clip(gray.astype(np.int16) + 100, 0, 255).astype(np.uint8)\n",
    "low_cont   = np.clip(gray.astype(np.float64) * 0.3 + 100, 0, 255).astype(np.uint8)\n",
    "\n",
    "show_with_hist(dark_img, gray, bright_img, low_cont,\n",
    "               titles=[\"Dark\", \"Original\", \"Bright\", \"Low contrast\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RGB histogram overlay\n",
    "\n",
    "For color images, we can plot the histogram of each channel on the same axes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 3))\n",
    "for ch, color in zip(range(3), [\"red\", \"green\", \"blue\"]):\n",
    "    h, _ = np.histogram(img_color[:, :, ch].ravel(), 256, [0, 256])\n",
    "    plt.fill_between(np.arange(256), h, alpha=0.35, color=color, label=color.capitalize())\n",
    "plt.xlabel(\"Pixel intensity\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.title(\"RGB histogram\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### Exercises\n\n**Exercise 7.1:** Compute the histogram of the grayscale image, then find and print:\n1. **Mode** (most frequent pixel value): the index with the highest count in the histogram. Use `np.argmax(hist)`.\n2. **90% intensity range**: find the intensity values at the 5th and 95th percentiles. This tells you the range that contains the middle 90% of pixels.\n\n*Hint:* Compute the **CDF** (cumulative sum of the histogram, `hist.cumsum()`), then normalize it by dividing by the total pixel count. The 5th percentile is the first index where `cdf >= 0.05`, and the 95th percentile where `cdf >= 0.95`. Use `np.searchsorted(cdf_normalized, 0.05)` to find these indices."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "**Exercise 7.2:** Compute the **negative** (complement) of the grayscale image: `negative = 255 - gray`.\nThen plot both histograms side by side (use two subplots or `show_with_hist`). Observe the relationship between the two histograms and write your finding as a comment.\n\n*Hint:* If the original has many pixels at intensity 50, where would those pixels appear in the negative's histogram?"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 8. Histogram Stretching\n",
    "\n",
    "Stretching linearly maps the actual intensity range $[f_{\\min}, f_{\\max}]$ to the full range $[0, 255]$:\n",
    "\n",
    "$$g = \\frac{f - f_{\\min}}{f_{\\max} - f_{\\min}} \\times 255$$\n",
    "\n",
    "This is effective when the image has a genuinely narrow intensity range."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a low-contrast image\n",
    "low = np.clip(gray.astype(np.float64) * 0.4 + 80, 0, 255).astype(np.uint8)\n",
    "print(f\"Low-contrast range: [{low.min()}, {low.max()}]\")\n",
    "\n",
    "# Stretch\n",
    "f_min, f_max = low.min(), low.max()\n",
    "stretched = ((low.astype(np.float64) - f_min) / (f_max - f_min) * 255).astype(np.uint8)\n",
    "print(f\"Stretched range:    [{stretched.min()}, {stretched.max()}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_with_hist(low, stretched, titles=[\"Low contrast\", \"Stretched\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### When stretching fails\n",
    "\n",
    "If even one pixel is 0 and another is 255, then $f_{\\min}=0, f_{\\max}=255$, and the formula simplifies to $g = f$ — no change."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Inject outlier pixels into the low-contrast image\nlow_with_outliers = low.copy()\nlow_with_outliers[0, 0] = 0\nlow_with_outliers[0, 1] = 255\n\nf_min2, f_max2 = low_with_outliers.min(), low_with_outliers.max()\nstretched2 = ((low_with_outliers.astype(np.float64) - f_min2) / (f_max2 - f_min2) * 255).astype(np.uint8)\n\nprint(f\"Range with outliers: [{f_min2}, {f_max2}]  → stretching has no effect\")\n\nshow_with_hist(low_with_outliers, stretched2,\n               titles=[\"With outliers\", \"After stretching (no change)\"])"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### Exercises\n\n**Exercise 8.1:** Implement **percentile-based stretching** — a version of histogram stretching that is robust to outliers.\n\nInstead of using the absolute min/max, use the **2nd and 98th percentiles** as boundaries:\n\n```python\nlo = np.percentile(img, 2)    # ignore the darkest 2%\nhi = np.percentile(img, 98)   # ignore the brightest 2%\n```\n\nThen apply the same stretching formula, but **clip** values outside `[lo, hi]` before stretching:\n\n$$g = \\frac{\\text{clip}(f, lo, hi) - lo}{hi - lo} \\times 255$$\n\nApply it to `low_with_outliers` and compare with basic stretching using `show_with_hist`."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 9. Histogram Equalization\n",
    "\n",
    "Equalization redistributes pixel intensities so the histogram becomes approximately **uniform**. Unlike stretching, it considers the full distribution — not just min/max.\n",
    "\n",
    "**Algorithm:**\n",
    "1. Compute histogram $h[k]$\n",
    "2. Compute CDF: $\\text{CDF}[k] = \\sum_{j=0}^{k} h[j]$\n",
    "3. Normalize: $T[k] = \\text{round}\\left(\\frac{\\text{CDF}[k] - \\text{CDF}_{\\min}}{N - \\text{CDF}_{\\min}} \\times 255\\right)$\n",
    "4. Apply as LUT: `result = T[img]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step-by-step equalization on the low-contrast image\n",
    "hist_low, _ = np.histogram(low.ravel(), 256, [0, 256])\n",
    "\n",
    "cdf = hist_low.cumsum()\n",
    "cdf_normalized = (cdf - cdf.min()) * 255 / (cdf.max() - cdf.min())\n",
    "cdf_normalized = cdf_normalized.astype(np.uint8)\n",
    "\n",
    "equalized = cdf_normalized[low]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing the CDF as a transfer function\n",
    "\n",
    "The normalized CDF **is** the LUT used for equalization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
    "\n",
    "# Histogram + CDF on twin axes\n",
    "ax1 = axes[0]\n",
    "ax2 = ax1.twinx()\n",
    "ax1.fill_between(np.arange(256), hist_low, alpha=0.5, label=\"Histogram\")\n",
    "ax2.plot(np.arange(256), cdf / cdf.max(), \"r-\", label=\"CDF\")\n",
    "ax1.set_xlabel(\"Pixel intensity\")\n",
    "ax1.set_ylabel(\"Count\")\n",
    "ax2.set_ylabel(\"CDF (normalized)\")\n",
    "ax1.set_title(\"Histogram and CDF\")\n",
    "ax1.legend(loc=\"upper left\")\n",
    "ax2.legend(loc=\"center right\")\n",
    "\n",
    "# Transfer function (the LUT)\n",
    "axes[1].plot(np.arange(256), cdf_normalized, label=\"Equalization LUT\")\n",
    "axes[1].plot(np.arange(256), np.arange(256), \"k--\", alpha=0.3, label=\"Identity\")\n",
    "axes[1].set_xlabel(\"Input\")\n",
    "axes[1].set_ylabel(\"Output\")\n",
    "axes[1].set_title(\"Transfer function\")\n",
    "axes[1].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_with_hist(low, equalized, titles=[\"Low contrast\", \"Equalized\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stretching vs Equalization\n",
    "\n",
    "Let's compare both methods side by side on the same low-contrast input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_images(low, stretched, equalized,\n",
    "            titles=[\"Low contrast\", \"Stretched\", \"Equalized\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### Exercises\n\n**Exercise 9.1:** Implement histogram equalization from scratch as a function `equalize(img)`.\n\nSteps (same as above):\n1. Compute the histogram: `np.histogram(img.ravel(), 256, [0, 256])`\n2. Compute the CDF: `hist.cumsum()`\n3. Normalize: `(cdf - cdf.min()) * 255 / (cdf.max() - cdf.min())`\n4. Cast to `uint8` and apply as LUT: `T[img]`\n\nTest it on the **original grayscale parrot** (not the artificial low-contrast version). Display original and equalized with their histograms using `show_with_hist`."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 10. HSV Color Space\n",
    "\n",
    "**HSV** (Hue, Saturation, Value) separates *color* from *intensity*, which is often more intuitive than RGB.\n",
    "\n",
    "We use `matplotlib.colors.rgb_to_hsv` and `hsv_to_rgb`:\n",
    "- Input/output are **float arrays in [0, 1]** (so divide by 255 first, multiply by 255 after)\n",
    "- Hue is in [0, 1] where 0 = red, 1/3 = green, 2/3 = blue, 1 = red again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hsv = rgb_to_hsv(img_color / 255.0)\n",
    "\n",
    "h_ch = hsv[:, :, 0]  # Hue        [0, 1]\n",
    "s_ch = hsv[:, :, 1]  # Saturation [0, 1]\n",
    "v_ch = hsv[:, :, 2]  # Value      [0, 1]\n",
    "\n",
    "# Hue needs the 'hsv' colormap; S and V are shown as grayscale\n",
    "fig, axes = plt.subplots(1, 4, figsize=(16, 4))\n",
    "axes[0].imshow(img_color);              axes[0].set_title(\"Original\")\n",
    "axes[1].imshow(h_ch, cmap=\"hsv\");       axes[1].set_title(\"Hue\")\n",
    "axes[2].imshow(s_ch, cmap=\"gray\");      axes[2].set_title(\"Saturation\")\n",
    "axes[3].imshow(v_ch, cmap=\"gray\");      axes[3].set_title(\"Value\")\n",
    "for ax in axes:\n",
    "    ax.axis(\"off\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hue shift\n",
    "\n",
    "Shifting hue rotates all colors around the color wheel. Since hue is cyclic, we use modulo 1.0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hsv_shifted = hsv.copy()\n",
    "hsv_shifted[:, :, 0] = (hsv_shifted[:, :, 0] + 1/3) % 1.0  # +120 degrees\n",
    "shifted_rgb = (hsv_to_rgb(hsv_shifted) * 255).astype(np.uint8)\n",
    "\n",
    "show_images(img_color, shifted_rgb, titles=[\"Original\", \"Hue +120°\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saturation manipulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adjust_saturation(img_rgb, factor):\n",
    "    \"\"\"Multiply saturation by factor, clip to [0, 1].\"\"\"\n",
    "    hsv_tmp = rgb_to_hsv(img_rgb / 255.0)\n",
    "    hsv_tmp[:, :, 1] = np.clip(hsv_tmp[:, :, 1] * factor, 0, 1)\n",
    "    return (hsv_to_rgb(hsv_tmp) * 255).astype(np.uint8)\n",
    "\n",
    "show_images(adjust_saturation(img_color, 0.3), img_color, adjust_saturation(img_color, 2.0),\n",
    "            titles=[\"Desaturated (×0.3)\", \"Original\", \"Boosted (×2.0)\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Value (brightness) manipulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adjust_value(img_rgb, factor):\n",
    "    \"\"\"Multiply Value channel by factor, clip to [0, 1].\"\"\"\n",
    "    hsv_tmp = rgb_to_hsv(img_rgb / 255.0)\n",
    "    hsv_tmp[:, :, 2] = np.clip(hsv_tmp[:, :, 2] * factor, 0, 1)\n",
    "    return (hsv_to_rgb(hsv_tmp) * 255).astype(np.uint8)\n",
    "\n",
    "show_images(adjust_value(img_color, 0.4), img_color, adjust_value(img_color, 1.5),\n",
    "            titles=[\"Darker (V×0.4)\", \"Original\", \"Lighter (V×1.5)\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Practical application: Equalize only the V channel\n",
    "\n",
    "Applying histogram equalization to each RGB channel independently can produce color artifacts. A better approach: convert to HSV, equalize only the Value channel (brightness), and convert back. This preserves the original colors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hsv_eq = rgb_to_hsv(img_color / 255.0)\n",
    "\n",
    "v_uint8 = (hsv_eq[:, :, 2] * 255).astype(np.uint8)\n",
    "hist_v, _ = np.histogram(v_uint8.ravel(), 256, [0, 256])\n",
    "cdf_v = hist_v.cumsum()\n",
    "cdf_v_norm = (cdf_v - cdf_v.min()) * 255 / (cdf_v.max() - cdf_v.min())\n",
    "v_equalized = cdf_v_norm[v_uint8].astype(np.uint8)\n",
    "\n",
    "hsv_eq[:, :, 2] = v_equalized / 255.0\n",
    "result_v_eq = (hsv_to_rgb(hsv_eq) * 255).astype(np.uint8)\n",
    "\n",
    "show_images(img_color, result_v_eq, titles=[\"Original\", \"V-channel equalized\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### Exercises\n\n**Exercise 10.1:** Compare two ways of getting a \"grayscale\" image:\n- **V channel**: `(hsv[:, :, 2] * 255).astype(np.uint8)` — takes the max of R, G, B\n- **Luma** (`Image.convert('L')`): uses the weighted formula $0.299R + 0.587G + 0.114B$\n\nExtract the V channel, and display it alongside `img_gray` (which we created via `convert('L')` in Section 1) using `show_images`. Do they look the same? Where do you see differences?\n\n*Hint:* Look at brightly colored regions — V = max(R,G,B) tends to be higher than the weighted luma average."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "**Exercise 10.2:** Create a 2×3 grid showing the original image and 5 hue-shifted versions (+60°, +120°, +180°, +240°, +300°). Label each with its shift angle.\n\n*Hint:* Hue is normalized to [0, 1], so +60° = +1/6, +120° = +2/6, etc. Use modulo to wrap: `(h + offset) % 1.0`."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}