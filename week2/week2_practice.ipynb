{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 2: Image Processing Basics — Lab Practice\n",
    "\n",
    "**Topics:** Pixels, Point Processing & Histograms\n",
    "\n",
    "This notebook accompanies the Week 2 lecture slides. We will load images as NumPy arrays, perform point processing operations, compute histograms, and explore color spaces — all hands-on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from matplotlib.colors import rgb_to_hsv, hsv_to_rgb\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Environment setup\n",
    "\n",
    "This notebook works both **locally** and on **Google Colab**.\n",
    "- **Local**: images are loaded from the repository's `images/` folder.\n",
    "- **Colab**: images are automatically downloaded from GitHub on first run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, urllib.request\n",
    "\n",
    "# Detect Google Colab\n",
    "IN_COLAB = \"google.colab\" in str(get_ipython()) if hasattr(__builtins__, \"__IPYTHON__\") else False\n",
    "\n",
    "# Image paths\n",
    "REPO_URL = \"https://raw.githubusercontent.com/HyeongminLEE/image-processing-tutorial/main\"\n",
    "IMAGE_DIR = \"images\"\n",
    "IMAGE_NAME = \"parrots_square.jpg\"\n",
    "\n",
    "if IN_COLAB:\n",
    "    os.makedirs(IMAGE_DIR, exist_ok=True)\n",
    "    url = f\"{REPO_URL}/{IMAGE_DIR}/{IMAGE_NAME}\"\n",
    "    dest = os.path.join(IMAGE_DIR, IMAGE_NAME)\n",
    "    if not os.path.exists(dest):\n",
    "        print(f\"Downloading {IMAGE_NAME} ...\")\n",
    "        urllib.request.urlretrieve(url, dest)\n",
    "        print(\"Done.\")\n",
    "    IMAGE_PATH = dest\n",
    "else:\n",
    "    # Local: image lives in the repo root's images/ folder\n",
    "    IMAGE_PATH = os.path.join(\"..\", IMAGE_DIR, IMAGE_NAME)\n",
    "\n",
    "GRAY_PATH = \"parrots_gray.jpg\"  # will be created in Section 1\n",
    "\n",
    "print(f\"Image path: {IMAGE_PATH}\")\n",
    "print(f\"Running on: {'Google Colab' if IN_COLAB else 'Local'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display helpers\n",
    "\n",
    "We define two utility functions used throughout this notebook so that visualization code stays minimal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_images(*imgs, titles=None, scale=4):\n",
    "    \"\"\"Display images in a single row.\n",
    "\n",
    "    Grayscale (2-D uint8) arrays automatically use a gray colormap.\n",
    "    *titles* is an optional list of strings, one per image.\n",
    "    \"\"\"\n",
    "    n = len(imgs)\n",
    "    fig, axes = plt.subplots(1, n, figsize=(scale * n, scale))\n",
    "    if n == 1:\n",
    "        axes = [axes]\n",
    "    for i, (ax, img) in enumerate(zip(axes, imgs)):\n",
    "        if img.ndim == 2:\n",
    "            ax.imshow(img, cmap=\"gray\", vmin=0, vmax=255)\n",
    "        else:\n",
    "            ax.imshow(img)\n",
    "        if titles:\n",
    "            ax.set_title(titles[i])\n",
    "        ax.axis(\"off\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def show_with_hist(*imgs, titles=None, scale=4):\n",
    "    \"\"\"Display grayscale images (top row) with their histograms (bottom row).\"\"\"\n",
    "    n = len(imgs)\n",
    "    fig, axes = plt.subplots(2, n, figsize=(scale * n, scale * 1.5))\n",
    "    if n == 1:\n",
    "        axes = axes.reshape(2, 1)\n",
    "    for i, img in enumerate(imgs):\n",
    "        axes[0, i].imshow(img, cmap=\"gray\", vmin=0, vmax=255)\n",
    "        if titles:\n",
    "            axes[0, i].set_title(titles[i])\n",
    "        axes[0, i].axis(\"off\")\n",
    "        h, _ = np.histogram(img.ravel(), 256, [0, 256])\n",
    "        axes[1, i].fill_between(np.arange(256), h, alpha=0.7)\n",
    "        axes[1, i].set_xlim([0, 255])\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 0. NumPy Crash Course\n",
    "\n",
    "Images in Python are just **NumPy arrays**. Before touching any pixels, let's make sure we are comfortable with the basics.\n",
    "\n",
    "NumPy's core object is the **`ndarray`** — a fixed-size, homogeneous, N-dimensional array."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From a Python list\n",
    "a = np.array([1, 2, 3, 4, 5])\n",
    "print(\"a          =\", a)\n",
    "print(\"a.shape    =\", a.shape)      # (5,)  — 1-D, 5 elements\n",
    "print(\"a.ndim     =\", a.ndim)       # 1\n",
    "print(\"a.dtype    =\", a.dtype)      # int64 (default on most systems)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2-D array (matrix)\n",
    "b = np.array([[1, 2, 3],\n",
    "              [4, 5, 6]])\n",
    "print(\"b.shape =\", b.shape)         # (2, 3) — 2 rows, 3 columns\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handy constructors\n",
    "print(\"zeros :\", np.zeros((2, 3)))                 # all 0s\n",
    "print(\"ones  :\", np.ones((2, 3)))                  # all 1s\n",
    "print(\"arange:\", np.arange(0, 10, 2))              # [0, 2, 4, 6, 8]  (start, stop, step)\n",
    "print(\"linspace:\", np.linspace(0, 1, 5))           # [0, 0.25, 0.5, 0.75, 1]  (5 evenly spaced)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### dtype — data type\n",
    "\n",
    "Every element in an array has the **same type**. Common ones:\n",
    "\n",
    "| dtype | Description | Range |\n",
    "|---|---|---|\n",
    "| `uint8` | unsigned 8-bit int | 0 – 255 |\n",
    "| `int16` | signed 16-bit int | −32 768 – 32 767 |\n",
    "| `float64` | 64-bit float | ±1.8 × 10³⁰⁸ |\n",
    "\n",
    "Images are almost always **`uint8`**. We cast to wider types before arithmetic to avoid overflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "u = np.array([200, 100], dtype=np.uint8)\n",
    "print(\"uint8 200 + 100 =\", u[0] + u[1])            # 44!  (wraps around 256)\n",
    "\n",
    "s = u.astype(np.int16)                               # cast to int16 first\n",
    "print(\"int16 200 + 100 =\", s[0] + s[1])             # 300  (correct)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Indexing & slicing\n",
    "\n",
    "Works like Python lists, but extended to multiple dimensions with **comma-separated indices**: `array[row, col]`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = np.arange(12).reshape(3, 4)   # 3×4 matrix  [0..11]\n",
    "print(m)\n",
    "print()\n",
    "\n",
    "print(\"m[0, 2]   =\", m[0, 2])      # single element: row 0, col 2\n",
    "print(\"m[1]      =\", m[1])          # entire row 1\n",
    "print(\"m[:, 0]   =\", m[:, 0])       # entire column 0  (: means \"all rows\")\n",
    "print(\"m[0:2, 1:3] =\\n\", m[0:2, 1:3])  # sub-matrix: rows 0-1, cols 1-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Negative indexing & step\n",
    "print(\"last row  =\", m[-1])         # last row\n",
    "print(\"reversed  =\", m[::-1])       # rows in reverse order (we'll use this to flip images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Element-wise arithmetic & broadcasting\n",
    "\n",
    "Arithmetic operators (`+`, `-`, `*`, `/`, `**`) work **element-by-element**.\n",
    "\n",
    "When shapes differ, NumPy **broadcasts** the smaller array — e.g., adding a scalar to every element."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v = np.array([10, 20, 30])\n",
    "\n",
    "print(\"v + 5   =\", v + 5)           # scalar broadcast: [15, 25, 35]\n",
    "print(\"v * 2   =\", v * 2)           # [20, 40, 60]\n",
    "print(\"v ** 2  =\", v ** 2)          # [100, 400, 900]\n",
    "print(\"v > 15  =\", v > 15)          # boolean array: [False, True, True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Two arrays of the same shape → element-wise\n",
    "w = np.array([1, 2, 3])\n",
    "print(\"v + w =\", v + w)             # [11, 22, 33]\n",
    "print(\"v * w =\", v * w)             # [10, 40, 90]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Useful functions: clip, min, max, sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array([-10, 50, 200, 300])\n",
    "\n",
    "print(\"clip(x, 0, 255) =\", np.clip(x, 0, 255))   # clamp values to [0, 255]\n",
    "print(\"min =\", x.min(), \" max =\", x.max(), \" sum =\", x.sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reshape, ravel, flatten\n",
    "\n",
    "These change the **logical shape** without copying data (except `flatten` which always copies)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.arange(12)\n",
    "print(\"a         =\", a)             # [0, 1, ..., 11]   shape (12,)\n",
    "\n",
    "b = a.reshape(3, 4)                  # → shape (3, 4)\n",
    "print(\"reshaped  =\\n\", b)\n",
    "\n",
    "print(\"ravel     =\", b.ravel())      # back to 1-D  (view, no copy)\n",
    "print(\"flatten   =\", b.flatten())    # back to 1-D  (always copies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding / removing dimensions: expand_dims & squeeze\n",
    "\n",
    "These are important when working with images:\n",
    "- A grayscale image has shape `(H, W)` — but some functions expect `(H, W, 1)`.\n",
    "- `np.expand_dims(arr, axis)` inserts a **new axis of size 1** at the given position.\n",
    "- `np.squeeze(arr)` removes **all axes of size 1**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.zeros((4, 5))               # shape (4, 5)\n",
    "print(\"original shape   :\", a.shape)\n",
    "\n",
    "# expand_dims — add a dimension\n",
    "b = np.expand_dims(a, axis=2)       # (4, 5) → (4, 5, 1)\n",
    "print(\"expand axis=2    :\", b.shape)\n",
    "\n",
    "c = np.expand_dims(a, axis=0)       # (4, 5) → (1, 4, 5)\n",
    "print(\"expand axis=0    :\", c.shape)\n",
    "\n",
    "# Shorthand with None / np.newaxis  (same effect)\n",
    "d = a[:, :, None]                   # (4, 5) → (4, 5, 1)\n",
    "print(\"[:, :, None]     :\", d.shape)\n",
    "\n",
    "e = a[None, :, :]                   # (4, 5) → (1, 4, 5)\n",
    "print(\"[None, :, :]     :\", e.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# squeeze — remove size-1 dimensions\n",
    "f = np.zeros((1, 4, 5, 1))\n",
    "print(\"before squeeze:\", f.shape)    # (1, 4, 5, 1)\n",
    "print(\"after  squeeze:\", np.squeeze(f).shape)  # (4, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Concatenate & stack\n",
    "\n",
    "- `np.concatenate` joins arrays along an **existing** axis.\n",
    "- `np.stack` joins arrays along a **new** axis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = np.ones((2, 3))\n",
    "q = np.zeros((2, 3))\n",
    "\n",
    "# concatenate along axis 0 (stack rows)\n",
    "r = np.concatenate([p, q], axis=0)\n",
    "print(\"concat axis=0 :\", r.shape)   # (4, 3)\n",
    "print(r)\n",
    "print()\n",
    "\n",
    "# concatenate along axis 1 (append columns)\n",
    "s = np.concatenate([p, q], axis=1)\n",
    "print(\"concat axis=1 :\", s.shape)   # (2, 6)\n",
    "print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stack — adds a NEW axis\n",
    "t = np.stack([p, q], axis=0)\n",
    "print(\"stack axis=0 :\", t.shape)    # (2, 2, 3) — two (2,3) arrays stacked into a new dim\n",
    "\n",
    "u = np.stack([p, q], axis=2)\n",
    "print(\"stack axis=2 :\", u.shape)    # (2, 3, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A common image use-case: build an RGB image from three single-channel arrays.\n",
    "\n",
    "```python\n",
    "rgb = np.stack([r_channel, g_channel, b_channel], axis=2)  # (H, W, 3)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercises\n",
    "\n",
    "**Exercise 0.1:** Create a 1-D array of integers from 0 to 255, reshape it to `(16, 16)`, and print its shape.\n",
    "Then slice out the center 8×8 block and compute its mean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 0.2:** Given two arrays `a = np.arange(4)` (shape `(4,)`) and `b = np.arange(3)` (shape `(3,)`),\n",
    "use `expand_dims` (or `None` indexing) and broadcasting to compute the **outer product** — a `(4, 3)` matrix where element `[i, j] = a[i] * b[j]`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 1. Loading and Exploring Images\n",
    "\n",
    "We use **PIL** (`Pillow`) to open image files and immediately convert them to NumPy arrays. This gives us full control through array indexing and arithmetic.\n",
    "\n",
    "Key functions:\n",
    "- `Image.open(path)` — returns a PIL Image object\n",
    "- `np.array(pil_img)` — converts it to a NumPy ndarray\n",
    "- `.shape`, `.dtype`, `.min()`, `.max()` — basic array inspection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_color = np.array(Image.open(IMAGE_PATH))\n",
    "\n",
    "print(f\"Shape : {img_color.shape}\")   # (H, W, C)\n",
    "print(f\"Dtype : {img_color.dtype}\")   # uint8\n",
    "print(f\"Min   : {img_color.min()}\")\n",
    "print(f\"Max   : {img_color.max()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_images(img_color, titles=[\"Color image (RGB)\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating and saving a grayscale version\n",
    "\n",
    "`Image.convert('L')` uses the ITU-R 601-2 luma formula:\n",
    "\n",
    "$$L = 0.299 R + 0.587 G + 0.114 B$$\n",
    "\n",
    "We save it to disk so we can load it directly in later sections."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_gray = np.array(Image.open(IMAGE_PATH).convert(\"L\"))\n",
    "\n",
    "print(f\"Shape : {img_gray.shape}\")   # (H, W) — no channel dimension\n",
    "print(f\"Dtype : {img_gray.dtype}\")\n",
    "\n",
    "# Save for later use\n",
    "Image.fromarray(img_gray).save(GRAY_PATH)\n",
    "print(f\"Saved grayscale image to {GRAY_PATH}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_images(img_gray, titles=[\"Grayscale image\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accessing individual pixels\n",
    "\n",
    "- Color pixel → a 1D array of 3 values `[R, G, B]`\n",
    "- Grayscale pixel → a single scalar value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "row, col = 100, 200\n",
    "\n",
    "print(f\"Color pixel at ({row}, {col}): {img_color[row, col]}\")\n",
    "print(f\"Gray  pixel at ({row}, {col}): {img_gray[row, col]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 2. Channel Extraction\n",
    "\n",
    "An RGB image has 3 channels stored along axis 2. We can slice them out individually.\n",
    "\n",
    "When displaying a single channel with `imshow`, use `cmap='gray'` — otherwise matplotlib applies a colormap that can be misleading."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_channel = img_color[:, :, 0]\n",
    "g_channel = img_color[:, :, 1]\n",
    "b_channel = img_color[:, :, 2]\n",
    "\n",
    "show_images(img_color, r_channel, g_channel, b_channel,\n",
    "            titles=[\"Original\", \"Red channel\", \"Green channel\", \"Blue channel\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercises\n",
    "\n",
    "**Exercise 2.1:** Create three *color* images that isolate each channel: a red-only image (G and B set to 0), a green-only image, and a blue-only image. Display all four (original + 3 filtered) in a 1×4 grid.\n",
    "\n",
    "*Hint:* Start with `np.zeros_like(img_color)` and copy the desired channel into it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 3. Flip, Rotate, and Crop\n",
    "\n",
    "NumPy slicing gives us geometric transforms for free:\n",
    "\n",
    "| Operation | Code |\n",
    "|---|---|\n",
    "| Vertical flip | `img[::-1]` |\n",
    "| Horizontal flip | `img[:, ::-1]` |\n",
    "| 90° rotation | `np.rot90(img)` |\n",
    "| Crop | `img[y1:y2, x1:x2]` |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_images(img_color, img_color[:, ::-1], img_color[::-1], np.rot90(img_color),\n",
    "            titles=[\"Original\", \"H-flip\", \"V-flip\", \"Rot 90°\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cropping\n",
    "\n",
    "Remember the coordinate order: `img[row_start:row_end, col_start:col_end]`, i.e., **y first, x second**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "H, W = img_color.shape[:2]\n",
    "cropped = img_color[H//4 : 3*H//4, W//4 : 3*W//4]\n",
    "\n",
    "show_images(img_color, cropped,\n",
    "            titles=[f\"Original ({H}×{W})\", f\"Center crop ({cropped.shape[0]}×{cropped.shape[1]})\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercises\n",
    "\n",
    "**Exercise 3.1:** Rotate the image by 180° using **only slicing** (do not use `np.rot90`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 3.2:** Crop a region of your choice, then create a 1×2 figure showing the crop and its horizontally-flipped version."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 4. Point Processing: Arithmetic Operations\n",
    "\n",
    "Point processing transforms each pixel **independently**: $g(x,y) = T[f(x,y)]$.\n",
    "\n",
    "The simplest transforms are arithmetic: add, subtract, multiply.\n",
    "\n",
    "> **Critical:** Images are stored as `uint8` (0–255). Arithmetic can overflow or underflow. Always **cast to a wider type first**, then **clip** back to [0, 255]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gray = np.array(Image.open(GRAY_PATH))\n",
    "print(f\"Shape: {gray.shape}, dtype: {gray.dtype}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Brightness: Add / Subtract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bright = np.clip(gray.astype(np.int16) + 80, 0, 255).astype(np.uint8)\n",
    "dark   = np.clip(gray.astype(np.int16) - 80, 0, 255).astype(np.uint8)\n",
    "\n",
    "show_images(dark, gray, bright, titles=[\"Darker (−80)\", \"Original\", \"Brighter (+80)\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Contrast: Multiply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "high_contrast = np.clip(gray.astype(np.float64) * 2.0, 0, 255).astype(np.uint8)\n",
    "low_contrast  = (gray.astype(np.float64) * 0.5).astype(np.uint8)\n",
    "\n",
    "show_images(low_contrast, gray, high_contrast,\n",
    "            titles=[\"×0.5 (low contrast)\", \"Original\", \"×2.0 (high contrast)\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Complement / Negative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "negative = 255 - gray  # uint8 subtraction is safe here since 255 >= any pixel\n",
    "\n",
    "show_images(gray, negative, titles=[\"Original\", \"Negative (255 − f)\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Why casting matters: uint8 overflow demo\n",
    "\n",
    "`uint8` arithmetic **wraps around** modulo 256. For example, `200 + 100 = 44` (not 300). This produces garbage results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bad_result  = gray + np.uint8(200)                                       # WRONG: uint8 overflow\n",
    "good_result = np.clip(gray.astype(np.int16) + 200, 0, 255).astype(np.uint8)  # CORRECT\n",
    "\n",
    "show_images(gray, bad_result, good_result,\n",
    "            titles=[\"Original\", \"uint8 overflow (WRONG)\", \"With clipping (CORRECT)\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing transfer functions\n",
    "\n",
    "A transfer function maps each input intensity to an output intensity. We can plot them on a 256×256 grid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.arange(256)\n",
    "\n",
    "plt.figure(figsize=(5, 5))\n",
    "plt.plot(x, x, \"k--\", label=\"Identity\")\n",
    "plt.plot(x, np.clip(x + 80, 0, 255), label=\"+80\")\n",
    "plt.plot(x, np.clip(x - 80, 0, 255), label=\"−80\")\n",
    "plt.plot(x, np.clip(x * 2, 0, 255), label=\"×2\")\n",
    "plt.plot(x, (x * 0.5).astype(int), label=\"×0.5\")\n",
    "plt.xlabel(\"Input intensity\")\n",
    "plt.ylabel(\"Output intensity\")\n",
    "plt.title(\"Transfer functions\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercises\n",
    "\n",
    "**Exercise 4.1:** Create a \"high-contrast negative\" of the grayscale image: first invert it (`255 − f`), then multiply by 1.5 with proper clipping. Display the original and the result side by side."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 4.2:** Apply brightness adjustment (+60) to the **color** image (all three channels). Make sure to handle overflow correctly. Display before and after."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 5. Gamma Correction\n",
    "\n",
    "Gamma correction applies a **power-law** transform:\n",
    "\n",
    "$$g = 255 \\left(\\frac{f}{255}\\right)^\\gamma$$\n",
    "\n",
    "- $\\gamma < 1$: brightens dark regions (expands shadows)\n",
    "- $\\gamma = 1$: identity (no change)\n",
    "- $\\gamma > 1$: darkens the image (compresses shadows)\n",
    "\n",
    "We normalize to [0, 1], apply the power, then scale back to [0, 255]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.arange(256)\n",
    "\n",
    "plt.figure(figsize=(5, 5))\n",
    "plt.plot(x, x, \"k--\", label=\"γ = 1.0 (identity)\")\n",
    "for gamma in [0.3, 0.5, 2.0, 3.0]:\n",
    "    plt.plot(x, 255 * (x / 255.0) ** gamma, label=f\"γ = {gamma}\")\n",
    "plt.xlabel(\"Input\")\n",
    "plt.ylabel(\"Output\")\n",
    "plt.title(\"Gamma curves\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_gamma(img, gamma):\n",
    "    \"\"\"Apply gamma correction to a uint8 image (grayscale or color).\"\"\"\n",
    "    return (255 * (img / 255.0) ** gamma).astype(np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_images(apply_gamma(gray, 0.4), gray, apply_gamma(gray, 2.5),\n",
    "            titles=[\"γ = 0.4 (brighten)\", \"Original\", \"γ = 2.5 (darken)\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gamma on a color image\n",
    "\n",
    "The same function works element-wise on all three channels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_images(apply_gamma(img_color, 0.4), img_color, apply_gamma(img_color, 2.5),\n",
    "            titles=[\"γ = 0.4\", \"Original\", \"γ = 2.5\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercises\n",
    "\n",
    "**Exercise 5.1:** Apply 5 different gamma values (0.2, 0.5, 1.0, 2.0, 5.0) to the grayscale image. Display all 5 results in a single 1×5 grid with their gamma values as titles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 6. Lookup Tables (LUT)\n",
    "\n",
    "Any point transform $T: [0,255] \\to [0,255]$ can be stored as an array of 256 entries. Applying it to an image is then a single **fancy-indexing** operation:\n",
    "\n",
    "```python\n",
    "T = np.array([...])  # shape (256,), dtype uint8\n",
    "result = T[img]       # each pixel used as an index\n",
    "```\n",
    "\n",
    "This is extremely fast because there are no per-pixel arithmetic operations at runtime — just table lookups."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Threshold LUT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "T_thresh = np.zeros(256, dtype=np.uint8)\n",
    "T_thresh[128:] = 255\n",
    "\n",
    "show_images(gray, T_thresh[gray], titles=[\"Original\", \"Threshold at 128\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### More LUT examples: Solarize & Posterize\n",
    "\n",
    "- **Solarize**: Invert pixels above a threshold → creates an \"X\" shaped transfer function\n",
    "- **Posterize** (4 levels): Quantize 256 grey levels into just 4 steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.arange(256)\n",
    "\n",
    "# Solarize: invert pixels above 128\n",
    "T_solar = x.copy().astype(np.uint8)\n",
    "T_solar[128:] = 255 - T_solar[128:]\n",
    "\n",
    "# Posterize: 4 levels (0, 85, 170, 255)\n",
    "T_poster = np.zeros(256, dtype=np.uint8)\n",
    "T_poster[0:64]    = 0\n",
    "T_poster[64:128]  = 85\n",
    "T_poster[128:192] = 170\n",
    "T_poster[192:256] = 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_images(T_thresh[gray], T_solar[gray], T_poster[gray],\n",
    "            titles=[\"Threshold\", \"Solarize\", \"Posterize (4 levels)\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also visualize the transfer functions (LUTs) themselves as line plots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 3, figsize=(12, 3))\n",
    "for ax, lut, name in zip(axes, [T_thresh, T_solar, T_poster],\n",
    "                          [\"Threshold\", \"Solarize\", \"Posterize\"]):\n",
    "    ax.plot(x, lut)\n",
    "    ax.plot(x, x, \"k--\", alpha=0.3)\n",
    "    ax.set_title(name)\n",
    "    ax.set_xlabel(\"Input\")\n",
    "    ax.set_ylabel(\"Output\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gamma as a LUT\n",
    "\n",
    "Any formula-based transform can also be pre-computed as a LUT. This is especially useful when applying the same transform to many images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gamma_val = 0.4\n",
    "T_gamma = (255 * (np.arange(256) / 255.0) ** gamma_val).astype(np.uint8)\n",
    "\n",
    "lut_result    = T_gamma[gray]\n",
    "direct_result = apply_gamma(gray, gamma_val)\n",
    "\n",
    "print(f\"LUT vs direct — identical? {np.array_equal(lut_result, direct_result)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercises\n",
    "\n",
    "**Exercise 6.1:** Build a custom piecewise LUT:\n",
    "- Input 0–63 → Output 0\n",
    "- Input 64–191 → Linear ramp from 0 to 255\n",
    "- Input 192–255 → Output 255\n",
    "\n",
    "Plot the transfer function and apply it to the grayscale image.\n",
    "\n",
    "*Hint:* `np.linspace(0, 255, 128).astype(np.uint8)` gives you 128 evenly spaced values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 6.2:** Create a \"warm tone\" effect on the **color** image by applying different LUTs per channel: slightly boost red (gamma 0.8), keep green unchanged (identity), and slightly reduce blue (gamma 1.3). Display before and after."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 7. Histograms\n",
    "\n",
    "A histogram counts how many pixels have each intensity value (0–255). It reveals the **contrast characteristics** of an image at a glance.\n",
    "\n",
    "Key function: `np.histogram(img.ravel(), bins=256, range=[0, 256])`\n",
    "\n",
    "- `.ravel()` flattens the image to 1D (required by `np.histogram`)\n",
    "- `bins=256` gives one bin per grey level\n",
    "- Returns `(hist, bin_edges)` — we typically ignore `bin_edges`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist, bins = np.histogram(gray.ravel(), 256, [0, 256])\n",
    "\n",
    "plt.figure(figsize=(8, 3))\n",
    "plt.fill_between(np.arange(256), hist, alpha=0.7)\n",
    "plt.xlabel(\"Pixel intensity\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.title(\"Histogram of grayscale image\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Histogram shapes tell a story\n",
    "\n",
    "Let's create dark, bright, and low-contrast versions and compare their histograms using `show_with_hist`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dark_img   = np.clip(gray.astype(np.float64) * 0.4, 0, 255).astype(np.uint8)\n",
    "bright_img = np.clip(gray.astype(np.int16) + 100, 0, 255).astype(np.uint8)\n",
    "low_cont   = np.clip(gray.astype(np.float64) * 0.3 + 100, 0, 255).astype(np.uint8)\n",
    "\n",
    "show_with_hist(dark_img, gray, bright_img, low_cont,\n",
    "               titles=[\"Dark\", \"Original\", \"Bright\", \"Low contrast\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RGB histogram overlay\n",
    "\n",
    "For color images, we can plot the histogram of each channel on the same axes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 3))\n",
    "for ch, color in zip(range(3), [\"red\", \"green\", \"blue\"]):\n",
    "    h, _ = np.histogram(img_color[:, :, ch].ravel(), 256, [0, 256])\n",
    "    plt.fill_between(np.arange(256), h, alpha=0.35, color=color, label=color.capitalize())\n",
    "plt.xlabel(\"Pixel intensity\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.title(\"RGB histogram\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercises\n",
    "\n",
    "**Exercise 7.1:** Compute the histogram of the grayscale image, then find and print:\n",
    "1. The most frequent pixel value (mode)\n",
    "2. The range `[lo, hi]` that contains 90% of all pixels (use the CDF: find the 5th and 95th percentile bins)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 7.2:** Plot the histograms of the original grayscale image and its negative side by side. What is the relationship between the two? Write your answer as a comment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 8. Histogram Stretching\n",
    "\n",
    "Stretching linearly maps the actual intensity range $[f_{\\min}, f_{\\max}]$ to the full range $[0, 255]$:\n",
    "\n",
    "$$g = \\frac{f - f_{\\min}}{f_{\\max} - f_{\\min}} \\times 255$$\n",
    "\n",
    "This is effective when the image has a genuinely narrow intensity range."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a low-contrast image\n",
    "low = np.clip(gray.astype(np.float64) * 0.4 + 80, 0, 255).astype(np.uint8)\n",
    "print(f\"Low-contrast range: [{low.min()}, {low.max()}]\")\n",
    "\n",
    "# Stretch\n",
    "f_min, f_max = low.min(), low.max()\n",
    "stretched = ((low.astype(np.float64) - f_min) / (f_max - f_min) * 255).astype(np.uint8)\n",
    "print(f\"Stretched range:    [{stretched.min()}, {stretched.max()}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_with_hist(low, stretched, titles=[\"Low contrast\", \"Stretched\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### When stretching fails\n",
    "\n",
    "If even one pixel is 0 and another is 255, then $f_{\\min}=0, f_{\\max}=255$, and the formula simplifies to $g = f$ — no change."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inject outlier pixels into the low-contrast image\n",
    "low_with_outliers = low.copy()\n",
    "low_with_outliers[0, 0] = 0\n",
    "low_with_outliers[0, 1] = 255\n",
    "\n",
    "f_min2, f_max2 = low_with_outliers.min(), low_with_outliers.max()\n",
    "stretched2 = ((low_with_outliers.astype(np.float64) - f_min2) / (f_max2 - f_min2) * 255).astype(np.uint8)\n",
    "\n",
    "print(f\"Range with outliers: [{f_min2}, {f_max2}]\")\n",
    "print(f\"Stretching produces identical image? {np.array_equal(low_with_outliers, stretched2)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercises\n",
    "\n",
    "**Exercise 8.1:** Implement **percentile-based stretching**: use the 2nd and 98th percentiles as boundaries instead of the absolute min/max. This makes stretching robust to outliers. Apply it to `low_with_outliers` and compare with basic stretching.\n",
    "\n",
    "*Hint:* `np.percentile(img, 2)` gives the 2nd percentile value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 9. Histogram Equalization\n",
    "\n",
    "Equalization redistributes pixel intensities so the histogram becomes approximately **uniform**. Unlike stretching, it considers the full distribution — not just min/max.\n",
    "\n",
    "**Algorithm:**\n",
    "1. Compute histogram $h[k]$\n",
    "2. Compute CDF: $\\text{CDF}[k] = \\sum_{j=0}^{k} h[j]$\n",
    "3. Normalize: $T[k] = \\text{round}\\left(\\frac{\\text{CDF}[k] - \\text{CDF}_{\\min}}{N - \\text{CDF}_{\\min}} \\times 255\\right)$\n",
    "4. Apply as LUT: `result = T[img]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step-by-step equalization on the low-contrast image\n",
    "hist_low, _ = np.histogram(low.ravel(), 256, [0, 256])\n",
    "\n",
    "cdf = hist_low.cumsum()\n",
    "cdf_normalized = (cdf - cdf.min()) * 255 / (cdf.max() - cdf.min())\n",
    "cdf_normalized = cdf_normalized.astype(np.uint8)\n",
    "\n",
    "equalized = cdf_normalized[low]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing the CDF as a transfer function\n",
    "\n",
    "The normalized CDF **is** the LUT used for equalization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
    "\n",
    "# Histogram + CDF on twin axes\n",
    "ax1 = axes[0]\n",
    "ax2 = ax1.twinx()\n",
    "ax1.fill_between(np.arange(256), hist_low, alpha=0.5, label=\"Histogram\")\n",
    "ax2.plot(np.arange(256), cdf / cdf.max(), \"r-\", label=\"CDF\")\n",
    "ax1.set_xlabel(\"Pixel intensity\")\n",
    "ax1.set_ylabel(\"Count\")\n",
    "ax2.set_ylabel(\"CDF (normalized)\")\n",
    "ax1.set_title(\"Histogram and CDF\")\n",
    "ax1.legend(loc=\"upper left\")\n",
    "ax2.legend(loc=\"center right\")\n",
    "\n",
    "# Transfer function (the LUT)\n",
    "axes[1].plot(np.arange(256), cdf_normalized, label=\"Equalization LUT\")\n",
    "axes[1].plot(np.arange(256), np.arange(256), \"k--\", alpha=0.3, label=\"Identity\")\n",
    "axes[1].set_xlabel(\"Input\")\n",
    "axes[1].set_ylabel(\"Output\")\n",
    "axes[1].set_title(\"Transfer function\")\n",
    "axes[1].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_with_hist(low, equalized, titles=[\"Low contrast\", \"Equalized\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stretching vs Equalization\n",
    "\n",
    "Let's compare both methods side by side on the same low-contrast input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_images(low, stretched, equalized,\n",
    "            titles=[\"Low contrast\", \"Stretched\", \"Equalized\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercises\n",
    "\n",
    "**Exercise 9.1:** Implement histogram equalization from scratch as a function `equalize(img)` that takes a **grayscale** uint8 image and returns the equalized image. Test it on the original grayscale parrot (not the artificial low-contrast version). Display original and equalized images with their histograms in a 2×2 grid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 10. HSV Color Space\n",
    "\n",
    "**HSV** (Hue, Saturation, Value) separates *color* from *intensity*, which is often more intuitive than RGB.\n",
    "\n",
    "We use `matplotlib.colors.rgb_to_hsv` and `hsv_to_rgb`:\n",
    "- Input/output are **float arrays in [0, 1]** (so divide by 255 first, multiply by 255 after)\n",
    "- Hue is in [0, 1] where 0 = red, 1/3 = green, 2/3 = blue, 1 = red again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hsv = rgb_to_hsv(img_color / 255.0)\n",
    "\n",
    "h_ch = hsv[:, :, 0]  # Hue        [0, 1]\n",
    "s_ch = hsv[:, :, 1]  # Saturation [0, 1]\n",
    "v_ch = hsv[:, :, 2]  # Value      [0, 1]\n",
    "\n",
    "# Hue needs the 'hsv' colormap; S and V are shown as grayscale\n",
    "fig, axes = plt.subplots(1, 4, figsize=(16, 4))\n",
    "axes[0].imshow(img_color);              axes[0].set_title(\"Original\")\n",
    "axes[1].imshow(h_ch, cmap=\"hsv\");       axes[1].set_title(\"Hue\")\n",
    "axes[2].imshow(s_ch, cmap=\"gray\");      axes[2].set_title(\"Saturation\")\n",
    "axes[3].imshow(v_ch, cmap=\"gray\");      axes[3].set_title(\"Value\")\n",
    "for ax in axes:\n",
    "    ax.axis(\"off\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hue shift\n",
    "\n",
    "Shifting hue rotates all colors around the color wheel. Since hue is cyclic, we use modulo 1.0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hsv_shifted = hsv.copy()\n",
    "hsv_shifted[:, :, 0] = (hsv_shifted[:, :, 0] + 1/3) % 1.0  # +120 degrees\n",
    "shifted_rgb = (hsv_to_rgb(hsv_shifted) * 255).astype(np.uint8)\n",
    "\n",
    "show_images(img_color, shifted_rgb, titles=[\"Original\", \"Hue +120°\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saturation manipulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adjust_saturation(img_rgb, factor):\n",
    "    \"\"\"Multiply saturation by factor, clip to [0, 1].\"\"\"\n",
    "    hsv_tmp = rgb_to_hsv(img_rgb / 255.0)\n",
    "    hsv_tmp[:, :, 1] = np.clip(hsv_tmp[:, :, 1] * factor, 0, 1)\n",
    "    return (hsv_to_rgb(hsv_tmp) * 255).astype(np.uint8)\n",
    "\n",
    "show_images(adjust_saturation(img_color, 0.3), img_color, adjust_saturation(img_color, 2.0),\n",
    "            titles=[\"Desaturated (×0.3)\", \"Original\", \"Boosted (×2.0)\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Value (brightness) manipulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adjust_value(img_rgb, factor):\n",
    "    \"\"\"Multiply Value channel by factor, clip to [0, 1].\"\"\"\n",
    "    hsv_tmp = rgb_to_hsv(img_rgb / 255.0)\n",
    "    hsv_tmp[:, :, 2] = np.clip(hsv_tmp[:, :, 2] * factor, 0, 1)\n",
    "    return (hsv_to_rgb(hsv_tmp) * 255).astype(np.uint8)\n",
    "\n",
    "show_images(adjust_value(img_color, 0.4), img_color, adjust_value(img_color, 1.5),\n",
    "            titles=[\"Darker (V×0.4)\", \"Original\", \"Lighter (V×1.5)\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Practical application: Equalize only the V channel\n",
    "\n",
    "Applying histogram equalization to each RGB channel independently can produce color artifacts. A better approach: convert to HSV, equalize only the Value channel (brightness), and convert back. This preserves the original colors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hsv_eq = rgb_to_hsv(img_color / 255.0)\n",
    "\n",
    "v_uint8 = (hsv_eq[:, :, 2] * 255).astype(np.uint8)\n",
    "hist_v, _ = np.histogram(v_uint8.ravel(), 256, [0, 256])\n",
    "cdf_v = hist_v.cumsum()\n",
    "cdf_v_norm = (cdf_v - cdf_v.min()) * 255 / (cdf_v.max() - cdf_v.min())\n",
    "v_equalized = cdf_v_norm[v_uint8].astype(np.uint8)\n",
    "\n",
    "hsv_eq[:, :, 2] = v_equalized / 255.0\n",
    "result_v_eq = (hsv_to_rgb(hsv_eq) * 255).astype(np.uint8)\n",
    "\n",
    "show_images(img_color, result_v_eq, titles=[\"Original\", \"V-channel equalized\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercises\n",
    "\n",
    "**Exercise 10.1:** Extract the V channel from the HSV image, convert it to uint8, and compare it with the grayscale image we created earlier using `Image.convert('L')`. Are they identical? Print whether they match and display both side by side. Explain the difference in a comment.\n",
    "\n",
    "*Hint:* `Image.convert('L')` uses the luma formula (weighted sum of R, G, B), while V = max(R, G, B)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 10.2:** Create a 2×3 grid showing the original image and 5 hue-shifted versions (+60°, +120°, +180°, +240°, +300°). Label each with its shift angle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
