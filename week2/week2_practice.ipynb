{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 2: Image Processing Basics — Lab Practice\n",
    "\n",
    "**Topics:** Pixels, Point Processing & Histograms\n",
    "\n",
    "This notebook accompanies the Week 2 lecture slides. We will load images as NumPy arrays, perform point processing operations, compute histograms, and explore color spaces — all hands-on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from matplotlib.colors import rgb_to_hsv, hsv_to_rgb\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### Environment setup\n\nThis notebook works both **locally** and on **Google Colab**.\n- **Local**: images are loaded from the repository's `images/` folder.\n- **Colab**: images are automatically downloaded from GitHub on first run."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "import os, urllib.request\n\n# Detect Google Colab\nIN_COLAB = \"google.colab\" in str(get_ipython()) if hasattr(__builtins__, \"__IPYTHON__\") else False\n\n# Image paths\nREPO_URL = \"https://raw.githubusercontent.com/HyeongminLEE/image-processing-tutorial/main\"\nIMAGE_DIR = \"images\"\nIMAGE_NAME = \"parrots_square.jpg\"\n\nif IN_COLAB:\n    os.makedirs(IMAGE_DIR, exist_ok=True)\n    url = f\"{REPO_URL}/{IMAGE_DIR}/{IMAGE_NAME}\"\n    dest = os.path.join(IMAGE_DIR, IMAGE_NAME)\n    if not os.path.exists(dest):\n        print(f\"Downloading {IMAGE_NAME} ...\")\n        urllib.request.urlretrieve(url, dest)\n        print(\"Done.\")\n    IMAGE_PATH = dest\nelse:\n    # Local: image lives in the repo root's images/ folder\n    IMAGE_PATH = os.path.join(\"..\", IMAGE_DIR, IMAGE_NAME)\n\nGRAY_PATH = \"parrots_gray.jpg\"  # will be created in Section 1\n\nprint(f\"Image path: {IMAGE_PATH}\")\nprint(f\"Running on: {'Google Colab' if IN_COLAB else 'Local'}\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 1. Loading and Exploring Images\n",
    "\n",
    "We use **PIL** (`Pillow`) to open image files and immediately convert them to NumPy arrays. This gives us full control through array indexing and arithmetic.\n",
    "\n",
    "Key functions:\n",
    "- `Image.open(path)` — returns a PIL Image object\n",
    "- `np.array(pil_img)` — converts it to a NumPy ndarray\n",
    "- `.shape`, `.dtype`, `.min()`, `.max()` — basic array inspection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_color = np.array(Image.open(IMAGE_PATH))\n",
    "\n",
    "print(f\"Shape : {img_color.shape}\")   # (H, W, C)\n",
    "print(f\"Dtype : {img_color.dtype}\")   # uint8\n",
    "print(f\"Min   : {img_color.min()}\")\n",
    "print(f\"Max   : {img_color.max()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5, 5))\n",
    "plt.imshow(img_color)\n",
    "plt.axis(\"off\")\n",
    "plt.title(\"Color image (RGB)\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating and saving a grayscale version\n",
    "\n",
    "`Image.convert('L')` uses the ITU-R 601-2 luma formula:\n",
    "\n",
    "$$L = 0.299 R + 0.587 G + 0.114 B$$\n",
    "\n",
    "We save it to disk so we can load it directly in later sections."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_gray = np.array(Image.open(IMAGE_PATH).convert(\"L\"))\n",
    "\n",
    "print(f\"Shape : {img_gray.shape}\")   # (H, W) — no channel dimension\n",
    "print(f\"Dtype : {img_gray.dtype}\")\n",
    "\n",
    "# Save for later use\n",
    "Image.fromarray(img_gray).save(GRAY_PATH)\n",
    "print(f\"Saved grayscale image to {GRAY_PATH}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5, 5))\n",
    "plt.imshow(img_gray, cmap=\"gray\", vmin=0, vmax=255)\n",
    "plt.axis(\"off\")\n",
    "plt.title(\"Grayscale image\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accessing individual pixels\n",
    "\n",
    "- Color pixel → a 1D array of 3 values `[R, G, B]`\n",
    "- Grayscale pixel → a single scalar value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "row, col = 100, 200\n",
    "\n",
    "print(f\"Color pixel at ({row}, {col}): {img_color[row, col]}\")\n",
    "print(f\"Gray  pixel at ({row}, {col}): {img_gray[row, col]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 2. Channel Extraction\n",
    "\n",
    "An RGB image has 3 channels stored along axis 2. We can slice them out individually.\n",
    "\n",
    "When displaying a single channel with `imshow`, use `cmap='gray'` — otherwise matplotlib applies a colormap that can be misleading."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_channel = img_color[:, :, 0]\n",
    "g_channel = img_color[:, :, 1]\n",
    "b_channel = img_color[:, :, 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 4, figsize=(16, 4))\n",
    "\n",
    "axes[0].imshow(img_color)\n",
    "axes[0].set_title(\"Original\")\n",
    "\n",
    "for ax, ch, name in zip(axes[1:], [r_channel, g_channel, b_channel], [\"Red\", \"Green\", \"Blue\"]):\n",
    "    ax.imshow(ch, cmap=\"gray\", vmin=0, vmax=255)\n",
    "    ax.set_title(f\"{name} channel\")\n",
    "\n",
    "for ax in axes:\n",
    "    ax.axis(\"off\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercises\n",
    "\n",
    "**Exercise 2.1:** Create three *color* images that isolate each channel: a red-only image (G and B set to 0), a green-only image, and a blue-only image. Display all four (original + 3 filtered) in a 1×4 grid.\n",
    "\n",
    "*Hint:* Start with `np.zeros_like(img_color)` and copy the desired channel into it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 3. Flip, Rotate, and Crop\n",
    "\n",
    "NumPy slicing gives us geometric transforms for free:\n",
    "\n",
    "| Operation | Code |\n",
    "|---|---|\n",
    "| Vertical flip | `img[::-1]` |\n",
    "| Horizontal flip | `img[:, ::-1]` |\n",
    "| 90° rotation | `np.rot90(img)` |\n",
    "| Crop | `img[y1:y2, x1:x2]` |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v_flip = img_color[::-1]\n",
    "h_flip = img_color[:, ::-1]\n",
    "rot90  = np.rot90(img_color)\n",
    "\n",
    "fig, axes = plt.subplots(1, 4, figsize=(16, 4))\n",
    "for ax, im, title in zip(axes,\n",
    "                          [img_color, h_flip, v_flip, rot90],\n",
    "                          [\"Original\", \"H-flip\", \"V-flip\", \"Rot 90°\"]):\n",
    "    ax.imshow(im)\n",
    "    ax.set_title(title)\n",
    "    ax.axis(\"off\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cropping\n",
    "\n",
    "Remember the coordinate order: `img[row_start:row_end, col_start:col_end]`, i.e., **y first, x second**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "H, W = img_color.shape[:2]\n",
    "cropped = img_color[H//4 : 3*H//4, W//4 : 3*W//4]\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(10, 5))\n",
    "axes[0].imshow(img_color)\n",
    "axes[0].set_title(f\"Original ({H}×{W})\")\n",
    "axes[1].imshow(cropped)\n",
    "axes[1].set_title(f\"Center crop ({cropped.shape[0]}×{cropped.shape[1]})\")\n",
    "for ax in axes:\n",
    "    ax.axis(\"off\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercises\n",
    "\n",
    "**Exercise 3.1:** Rotate the image by 180° using **only slicing** (do not use `np.rot90`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 3.2:** Crop a region of your choice, then create a 1×2 figure showing the crop and its horizontally-flipped version."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 4. Point Processing: Arithmetic Operations\n",
    "\n",
    "Point processing transforms each pixel **independently**: $g(x,y) = T[f(x,y)]$.\n",
    "\n",
    "The simplest transforms are arithmetic: add, subtract, multiply.\n",
    "\n",
    "> **Critical:** Images are stored as `uint8` (0–255). Arithmetic can overflow or underflow. Always **cast to a wider type first**, then **clip** back to [0, 255]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gray = np.array(Image.open(GRAY_PATH))\n",
    "print(f\"Shape: {gray.shape}, dtype: {gray.dtype}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Brightness: Add / Subtract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bright = np.clip(gray.astype(np.int16) + 80, 0, 255).astype(np.uint8)\n",
    "dark   = np.clip(gray.astype(np.int16) - 80, 0, 255).astype(np.uint8)\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(12, 4))\n",
    "for ax, im, title in zip(axes, [dark, gray, bright], [\"Darker (−80)\", \"Original\", \"Brighter (+80)\"]):\n",
    "    ax.imshow(im, cmap=\"gray\", vmin=0, vmax=255)\n",
    "    ax.set_title(title)\n",
    "    ax.axis(\"off\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Contrast: Multiply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "high_contrast = np.clip(gray.astype(np.float64) * 2.0, 0, 255).astype(np.uint8)\n",
    "low_contrast  = (gray.astype(np.float64) * 0.5).astype(np.uint8)\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(12, 4))\n",
    "for ax, im, title in zip(axes,\n",
    "                          [low_contrast, gray, high_contrast],\n",
    "                          [\"×0.5 (low contrast)\", \"Original\", \"×2.0 (high contrast)\"]):\n",
    "    ax.imshow(im, cmap=\"gray\", vmin=0, vmax=255)\n",
    "    ax.set_title(title)\n",
    "    ax.axis(\"off\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Complement / Negative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "negative = 255 - gray  # uint8 subtraction is safe here since 255 >= any pixel\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(8, 4))\n",
    "axes[0].imshow(gray, cmap=\"gray\", vmin=0, vmax=255)\n",
    "axes[0].set_title(\"Original\")\n",
    "axes[1].imshow(negative, cmap=\"gray\", vmin=0, vmax=255)\n",
    "axes[1].set_title(\"Negative (255 − f)\")\n",
    "for ax in axes:\n",
    "    ax.axis(\"off\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Why casting matters: uint8 overflow demo\n",
    "\n",
    "`uint8` arithmetic **wraps around** modulo 256. For example, `200 + 100 = 44` (not 300). This produces garbage results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BAD: direct uint8 addition\n",
    "bad_result = gray + np.uint8(200)\n",
    "\n",
    "# GOOD: cast first, clip, cast back\n",
    "good_result = np.clip(gray.astype(np.int16) + 200, 0, 255).astype(np.uint8)\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(12, 4))\n",
    "axes[0].imshow(gray, cmap=\"gray\", vmin=0, vmax=255)\n",
    "axes[0].set_title(\"Original\")\n",
    "axes[1].imshow(bad_result, cmap=\"gray\", vmin=0, vmax=255)\n",
    "axes[1].set_title(\"uint8 overflow (WRONG)\")\n",
    "axes[2].imshow(good_result, cmap=\"gray\", vmin=0, vmax=255)\n",
    "axes[2].set_title(\"With clipping (CORRECT)\")\n",
    "for ax in axes:\n",
    "    ax.axis(\"off\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing transfer functions\n",
    "\n",
    "A transfer function maps each input intensity to an output intensity. We can plot them on a 256×256 grid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.arange(256)\n",
    "\n",
    "plt.figure(figsize=(5, 5))\n",
    "plt.plot(x, x, \"k--\", label=\"Identity\")\n",
    "plt.plot(x, np.clip(x + 80, 0, 255), label=\"+80\")\n",
    "plt.plot(x, np.clip(x - 80, 0, 255), label=\"−80\")\n",
    "plt.plot(x, np.clip(x * 2, 0, 255), label=\"×2\")\n",
    "plt.plot(x, (x * 0.5).astype(int), label=\"×0.5\")\n",
    "plt.xlabel(\"Input intensity\")\n",
    "plt.ylabel(\"Output intensity\")\n",
    "plt.title(\"Transfer functions\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercises\n",
    "\n",
    "**Exercise 4.1:** Create a \"high-contrast negative\" of the grayscale image: first invert it (`255 − f`), then multiply by 1.5 with proper clipping. Display the original and the result side by side."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 4.2:** Apply brightness adjustment (+60) to the **color** image (all three channels). Make sure to handle overflow correctly. Display before and after."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 5. Gamma Correction\n",
    "\n",
    "Gamma correction applies a **power-law** transform:\n",
    "\n",
    "$$g = 255 \\left(\\frac{f}{255}\\right)^\\gamma$$\n",
    "\n",
    "- $\\gamma < 1$: brightens dark regions (expands shadows)\n",
    "- $\\gamma = 1$: identity (no change)\n",
    "- $\\gamma > 1$: darkens the image (compresses shadows)\n",
    "\n",
    "We normalize to [0, 1], apply the power, then scale back to [0, 255]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.arange(256)\n",
    "\n",
    "plt.figure(figsize=(5, 5))\n",
    "plt.plot(x, x, \"k--\", label=\"γ = 1.0 (identity)\")\n",
    "for gamma in [0.3, 0.5, 2.0, 3.0]:\n",
    "    y = 255 * (x / 255.0) ** gamma\n",
    "    plt.plot(x, y, label=f\"γ = {gamma}\")\n",
    "plt.xlabel(\"Input\")\n",
    "plt.ylabel(\"Output\")\n",
    "plt.title(\"Gamma curves\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_gamma(img, gamma):\n",
    "    \"\"\"Apply gamma correction to a uint8 image (grayscale or color).\"\"\"\n",
    "    return (255 * (img / 255.0) ** gamma).astype(np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gamma_low  = apply_gamma(gray, 0.4)\n",
    "gamma_high = apply_gamma(gray, 2.5)\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(12, 4))\n",
    "for ax, im, title in zip(axes,\n",
    "                          [gamma_low, gray, gamma_high],\n",
    "                          [\"γ = 0.4 (brighten)\", \"Original\", \"γ = 2.5 (darken)\"]):\n",
    "    ax.imshow(im, cmap=\"gray\", vmin=0, vmax=255)\n",
    "    ax.set_title(title)\n",
    "    ax.axis(\"off\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gamma on a color image\n",
    "\n",
    "The same function works element-wise on all three channels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "for ax, im, title in zip(axes,\n",
    "                          [apply_gamma(img_color, 0.4), img_color, apply_gamma(img_color, 2.5)],\n",
    "                          [\"γ = 0.4\", \"Original\", \"γ = 2.5\"]):\n",
    "    ax.imshow(im)\n",
    "    ax.set_title(title)\n",
    "    ax.axis(\"off\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercises\n",
    "\n",
    "**Exercise 5.1:** Apply 5 different gamma values (0.2, 0.5, 1.0, 2.0, 5.0) to the grayscale image. Display all 5 results in a single 1×5 grid with their gamma values as titles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 6. Lookup Tables (LUT)\n",
    "\n",
    "Any point transform $T: [0,255] \\to [0,255]$ can be stored as an array of 256 entries. Applying it to an image is then a single **fancy-indexing** operation:\n",
    "\n",
    "```python\n",
    "T = np.array([...])  # shape (256,), dtype uint8\n",
    "result = T[img]       # each pixel used as an index\n",
    "```\n",
    "\n",
    "This is extremely fast because there are no per-pixel arithmetic operations at runtime — just table lookups."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Threshold LUT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "T_thresh = np.zeros(256, dtype=np.uint8)\n",
    "T_thresh[128:] = 255\n",
    "\n",
    "thresh_result = T_thresh[gray]\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(12, 4))\n",
    "axes[0].imshow(gray, cmap=\"gray\", vmin=0, vmax=255)\n",
    "axes[0].set_title(\"Original\")\n",
    "axes[1].plot(np.arange(256), T_thresh)\n",
    "axes[1].set_title(\"Threshold LUT\")\n",
    "axes[1].set_xlabel(\"Input\")\n",
    "axes[1].set_ylabel(\"Output\")\n",
    "axes[2].imshow(thresh_result, cmap=\"gray\", vmin=0, vmax=255)\n",
    "axes[2].set_title(\"Result\")\n",
    "axes[0].axis(\"off\")\n",
    "axes[2].axis(\"off\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### More LUT examples: Solarize & Posterize\n",
    "\n",
    "- **Solarize**: Invert pixels above a threshold → creates an \"X\" shaped transfer function\n",
    "- **Posterize** (4 levels): Quantize 256 grey levels into just 4 steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.arange(256)\n",
    "\n",
    "# Solarize: invert pixels above 128\n",
    "T_solar = x.copy().astype(np.uint8)\n",
    "T_solar[128:] = 255 - T_solar[128:]\n",
    "\n",
    "# Posterize: 4 levels (0, 85, 170, 255)\n",
    "T_poster = np.zeros(256, dtype=np.uint8)\n",
    "T_poster[0:64]    = 0\n",
    "T_poster[64:128]  = 85\n",
    "T_poster[128:192] = 170\n",
    "T_poster[192:256] = 255\n",
    "\n",
    "fig, axes = plt.subplots(2, 3, figsize=(12, 8))\n",
    "\n",
    "# Row 0: transfer functions\n",
    "for ax, lut, name in zip(axes[0], [T_thresh, T_solar, T_poster],\n",
    "                          [\"Threshold\", \"Solarize\", \"Posterize (4 levels)\"]):\n",
    "    ax.plot(x, lut)\n",
    "    ax.plot(x, x, \"k--\", alpha=0.3)\n",
    "    ax.set_title(name)\n",
    "    ax.set_xlabel(\"Input\")\n",
    "    ax.set_ylabel(\"Output\")\n",
    "\n",
    "# Row 1: results\n",
    "for ax, lut in zip(axes[1], [T_thresh, T_solar, T_poster]):\n",
    "    ax.imshow(lut[gray], cmap=\"gray\", vmin=0, vmax=255)\n",
    "    ax.axis(\"off\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gamma as a LUT\n",
    "\n",
    "Any formula-based transform can also be pre-computed as a LUT. This is especially useful when applying the same transform to many images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gamma_val = 0.4\n",
    "T_gamma = (255 * (np.arange(256) / 255.0) ** gamma_val).astype(np.uint8)\n",
    "\n",
    "lut_result    = T_gamma[gray]\n",
    "direct_result = apply_gamma(gray, gamma_val)\n",
    "\n",
    "# Verify they are identical\n",
    "print(f\"LUT vs direct — identical? {np.array_equal(lut_result, direct_result)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercises\n",
    "\n",
    "**Exercise 6.1:** Build a custom piecewise LUT:\n",
    "- Input 0–63 → Output 0\n",
    "- Input 64–191 → Linear ramp from 0 to 255\n",
    "- Input 192–255 → Output 255\n",
    "\n",
    "Plot the transfer function and apply it to the grayscale image.\n",
    "\n",
    "*Hint:* `np.linspace(0, 255, 128).astype(np.uint8)` gives you 128 evenly spaced values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 6.2:** Create a \"warm tone\" effect on the **color** image by applying different LUTs per channel: slightly boost red (gamma 0.8), keep green unchanged (identity), and slightly reduce blue (gamma 1.3). Display before and after."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 7. Histograms\n",
    "\n",
    "A histogram counts how many pixels have each intensity value (0–255). It reveals the **contrast characteristics** of an image at a glance.\n",
    "\n",
    "Key function: `np.histogram(img.ravel(), bins=256, range=[0, 256])`\n",
    "\n",
    "- `.ravel()` flattens the image to 1D (required by `np.histogram`)\n",
    "- `bins=256` gives one bin per grey level\n",
    "- Returns `(hist, bin_edges)` — we typically ignore `bin_edges`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist, bins = np.histogram(gray.ravel(), 256, [0, 256])\n",
    "\n",
    "plt.figure(figsize=(8, 3))\n",
    "plt.fill_between(np.arange(256), hist, alpha=0.7)\n",
    "plt.xlabel(\"Pixel intensity\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.title(\"Histogram of grayscale image\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Histogram shapes tell a story\n",
    "\n",
    "Let's create dark, bright, and low-contrast versions and compare their histograms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dark_img    = np.clip(gray.astype(np.float64) * 0.4, 0, 255).astype(np.uint8)\n",
    "bright_img  = np.clip(gray.astype(np.int16) + 100, 0, 255).astype(np.uint8)\n",
    "low_cont    = np.clip(gray.astype(np.float64) * 0.3 + 100, 0, 255).astype(np.uint8)\n",
    "\n",
    "images = [dark_img, gray, bright_img, low_cont]\n",
    "titles = [\"Dark\", \"Original\", \"Bright\", \"Low contrast\"]\n",
    "\n",
    "fig, axes = plt.subplots(2, 4, figsize=(16, 6))\n",
    "\n",
    "for i, (im, title) in enumerate(zip(images, titles)):\n",
    "    axes[0, i].imshow(im, cmap=\"gray\", vmin=0, vmax=255)\n",
    "    axes[0, i].set_title(title)\n",
    "    axes[0, i].axis(\"off\")\n",
    "\n",
    "    h, _ = np.histogram(im.ravel(), 256, [0, 256])\n",
    "    axes[1, i].fill_between(np.arange(256), h, alpha=0.7)\n",
    "    axes[1, i].set_xlim([0, 255])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RGB histogram overlay\n",
    "\n",
    "For color images, we can plot the histogram of each channel on the same axes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 3))\n",
    "for ch, color in zip(range(3), [\"red\", \"green\", \"blue\"]):\n",
    "    h, _ = np.histogram(img_color[:, :, ch].ravel(), 256, [0, 256])\n",
    "    plt.fill_between(np.arange(256), h, alpha=0.35, color=color, label=color.capitalize())\n",
    "plt.xlabel(\"Pixel intensity\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.title(\"RGB histogram\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercises\n",
    "\n",
    "**Exercise 7.1:** Compute the histogram of the grayscale image, then find and print:\n",
    "1. The most frequent pixel value (mode)\n",
    "2. The range `[lo, hi]` that contains 90% of all pixels (use the CDF: find the 5th and 95th percentile bins)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 7.2:** Plot the histograms of the original grayscale image and its negative side by side. What is the relationship between the two? Write your answer as a comment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 8. Histogram Stretching\n",
    "\n",
    "Stretching linearly maps the actual intensity range $[f_{\\min}, f_{\\max}]$ to the full range $[0, 255]$:\n",
    "\n",
    "$$g = \\frac{f - f_{\\min}}{f_{\\max} - f_{\\min}} \\times 255$$\n",
    "\n",
    "This is effective when the image has a genuinely narrow intensity range."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a low-contrast image\n",
    "low = np.clip(gray.astype(np.float64) * 0.4 + 80, 0, 255).astype(np.uint8)\n",
    "print(f\"Low-contrast range: [{low.min()}, {low.max()}]\")\n",
    "\n",
    "# Stretch\n",
    "f_min, f_max = low.min(), low.max()\n",
    "stretched = ((low.astype(np.float64) - f_min) / (f_max - f_min) * 255).astype(np.uint8)\n",
    "print(f\"Stretched range:    [{stretched.min()}, {stretched.max()}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 2, figsize=(10, 7))\n",
    "\n",
    "axes[0, 0].imshow(low, cmap=\"gray\", vmin=0, vmax=255)\n",
    "axes[0, 0].set_title(\"Low contrast\")\n",
    "axes[0, 0].axis(\"off\")\n",
    "\n",
    "axes[0, 1].imshow(stretched, cmap=\"gray\", vmin=0, vmax=255)\n",
    "axes[0, 1].set_title(\"Stretched\")\n",
    "axes[0, 1].axis(\"off\")\n",
    "\n",
    "for ax, im in zip(axes[1], [low, stretched]):\n",
    "    h, _ = np.histogram(im.ravel(), 256, [0, 256])\n",
    "    ax.fill_between(np.arange(256), h, alpha=0.7)\n",
    "    ax.set_xlim([0, 255])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### When stretching fails\n",
    "\n",
    "If even one pixel is 0 and another is 255, then $f_{\\min}=0, f_{\\max}=255$, and the formula simplifies to $g = f$ — no change."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inject outlier pixels into the low-contrast image\n",
    "low_with_outliers = low.copy()\n",
    "low_with_outliers[0, 0] = 0\n",
    "low_with_outliers[0, 1] = 255\n",
    "\n",
    "f_min2, f_max2 = low_with_outliers.min(), low_with_outliers.max()\n",
    "stretched2 = ((low_with_outliers.astype(np.float64) - f_min2) / (f_max2 - f_min2) * 255).astype(np.uint8)\n",
    "\n",
    "print(f\"Range with outliers: [{f_min2}, {f_max2}]\")\n",
    "print(f\"Stretching produces identical image? {np.array_equal(low_with_outliers, stretched2)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercises\n",
    "\n",
    "**Exercise 8.1:** Implement **percentile-based stretching**: use the 2nd and 98th percentiles as boundaries instead of the absolute min/max. This makes stretching robust to outliers. Apply it to `low_with_outliers` and compare with basic stretching.\n",
    "\n",
    "*Hint:* `np.percentile(img, 2)` gives the 2nd percentile value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 9. Histogram Equalization\n",
    "\n",
    "Equalization redistributes pixel intensities so the histogram becomes approximately **uniform**. Unlike stretching, it considers the full distribution — not just min/max.\n",
    "\n",
    "**Algorithm:**\n",
    "1. Compute histogram $h[k]$\n",
    "2. Compute CDF: $\\text{CDF}[k] = \\sum_{j=0}^{k} h[j]$\n",
    "3. Normalize: $T[k] = \\text{round}\\left(\\frac{\\text{CDF}[k] - \\text{CDF}_{\\min}}{N - \\text{CDF}_{\\min}} \\times 255\\right)$\n",
    "4. Apply as LUT: `result = T[img]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step-by-step equalization on the low-contrast image\n",
    "hist_low, _ = np.histogram(low.ravel(), 256, [0, 256])\n",
    "\n",
    "cdf = hist_low.cumsum()\n",
    "cdf_normalized = (cdf - cdf.min()) * 255 / (cdf.max() - cdf.min())\n",
    "cdf_normalized = cdf_normalized.astype(np.uint8)\n",
    "\n",
    "equalized = cdf_normalized[low]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing the CDF as a transfer function\n",
    "\n",
    "The normalized CDF **is** the LUT used for equalization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
    "\n",
    "# Histogram + CDF on twin axes\n",
    "ax1 = axes[0]\n",
    "ax2 = ax1.twinx()\n",
    "ax1.fill_between(np.arange(256), hist_low, alpha=0.5, label=\"Histogram\")\n",
    "ax2.plot(np.arange(256), cdf / cdf.max(), \"r-\", label=\"CDF\")\n",
    "ax1.set_xlabel(\"Pixel intensity\")\n",
    "ax1.set_ylabel(\"Count\")\n",
    "ax2.set_ylabel(\"CDF (normalized)\")\n",
    "ax1.set_title(\"Histogram and CDF\")\n",
    "ax1.legend(loc=\"upper left\")\n",
    "ax2.legend(loc=\"center right\")\n",
    "\n",
    "# Transfer function (the LUT)\n",
    "axes[1].plot(np.arange(256), cdf_normalized, label=\"Equalization LUT\")\n",
    "axes[1].plot(np.arange(256), np.arange(256), \"k--\", alpha=0.3, label=\"Identity\")\n",
    "axes[1].set_xlabel(\"Input\")\n",
    "axes[1].set_ylabel(\"Output\")\n",
    "axes[1].set_title(\"Transfer function\")\n",
    "axes[1].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 2, figsize=(10, 7))\n",
    "\n",
    "axes[0, 0].imshow(low, cmap=\"gray\", vmin=0, vmax=255)\n",
    "axes[0, 0].set_title(\"Low contrast\")\n",
    "axes[0, 0].axis(\"off\")\n",
    "\n",
    "axes[0, 1].imshow(equalized, cmap=\"gray\", vmin=0, vmax=255)\n",
    "axes[0, 1].set_title(\"Equalized\")\n",
    "axes[0, 1].axis(\"off\")\n",
    "\n",
    "for ax, im in zip(axes[1], [low, equalized]):\n",
    "    h, _ = np.histogram(im.ravel(), 256, [0, 256])\n",
    "    ax.fill_between(np.arange(256), h, alpha=0.7)\n",
    "    ax.set_xlim([0, 255])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stretching vs Equalization\n",
    "\n",
    "Let's compare both methods side by side on the same low-contrast input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 3, figsize=(12, 4))\n",
    "for ax, im, title in zip(axes,\n",
    "                          [low, stretched, equalized],\n",
    "                          [\"Low contrast\", \"Stretched\", \"Equalized\"]):\n",
    "    ax.imshow(im, cmap=\"gray\", vmin=0, vmax=255)\n",
    "    ax.set_title(title)\n",
    "    ax.axis(\"off\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercises\n",
    "\n",
    "**Exercise 9.1:** Implement histogram equalization from scratch as a function `equalize(img)` that takes a **grayscale** uint8 image and returns the equalized image. Test it on the original grayscale parrot (not the artificial low-contrast version). Display original and equalized images with their histograms in a 2×2 grid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 10. HSV Color Space\n",
    "\n",
    "**HSV** (Hue, Saturation, Value) separates *color* from *intensity*, which is often more intuitive than RGB.\n",
    "\n",
    "We use `matplotlib.colors.rgb_to_hsv` and `hsv_to_rgb`:\n",
    "- Input/output are **float arrays in [0, 1]** (so divide by 255 first, multiply by 255 after)\n",
    "- Hue is in [0, 1] where 0 = red, 1/3 = green, 2/3 = blue, 1 = red again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hsv = rgb_to_hsv(img_color / 255.0)\n",
    "\n",
    "h_ch = hsv[:, :, 0]  # Hue        [0, 1]\n",
    "s_ch = hsv[:, :, 1]  # Saturation [0, 1]\n",
    "v_ch = hsv[:, :, 2]  # Value      [0, 1]\n",
    "\n",
    "fig, axes = plt.subplots(1, 4, figsize=(16, 4))\n",
    "axes[0].imshow(img_color)\n",
    "axes[0].set_title(\"Original\")\n",
    "axes[1].imshow(h_ch, cmap=\"hsv\", vmin=0, vmax=1)\n",
    "axes[1].set_title(\"Hue\")\n",
    "axes[2].imshow(s_ch, cmap=\"gray\", vmin=0, vmax=1)\n",
    "axes[2].set_title(\"Saturation\")\n",
    "axes[3].imshow(v_ch, cmap=\"gray\", vmin=0, vmax=1)\n",
    "axes[3].set_title(\"Value\")\n",
    "for ax in axes:\n",
    "    ax.axis(\"off\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hue shift\n",
    "\n",
    "Shifting hue rotates all colors around the color wheel. Since hue is cyclic, we use modulo 1.0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hsv_shifted = hsv.copy()\n",
    "hsv_shifted[:, :, 0] = (hsv_shifted[:, :, 0] + 1/3) % 1.0  # +120 degrees\n",
    "\n",
    "shifted_rgb = (hsv_to_rgb(hsv_shifted) * 255).astype(np.uint8)\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(10, 5))\n",
    "axes[0].imshow(img_color)\n",
    "axes[0].set_title(\"Original\")\n",
    "axes[1].imshow(shifted_rgb)\n",
    "axes[1].set_title(\"Hue +120°\")\n",
    "for ax in axes:\n",
    "    ax.axis(\"off\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saturation manipulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adjust_saturation(img_rgb, factor):\n",
    "    \"\"\"Multiply saturation by factor, clip to [0, 1].\"\"\"\n",
    "    hsv_tmp = rgb_to_hsv(img_rgb / 255.0)\n",
    "    hsv_tmp[:, :, 1] = np.clip(hsv_tmp[:, :, 1] * factor, 0, 1)\n",
    "    return (hsv_to_rgb(hsv_tmp) * 255).astype(np.uint8)\n",
    "\n",
    "desat = adjust_saturation(img_color, 0.3)\n",
    "boost = adjust_saturation(img_color, 2.0)\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "for ax, im, title in zip(axes,\n",
    "                          [desat, img_color, boost],\n",
    "                          [\"Desaturated (×0.3)\", \"Original\", \"Boosted (×2.0)\"]):\n",
    "    ax.imshow(im)\n",
    "    ax.set_title(title)\n",
    "    ax.axis(\"off\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Value (brightness) manipulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adjust_value(img_rgb, factor):\n",
    "    \"\"\"Multiply Value channel by factor, clip to [0, 1].\"\"\"\n",
    "    hsv_tmp = rgb_to_hsv(img_rgb / 255.0)\n",
    "    hsv_tmp[:, :, 2] = np.clip(hsv_tmp[:, :, 2] * factor, 0, 1)\n",
    "    return (hsv_to_rgb(hsv_tmp) * 255).astype(np.uint8)\n",
    "\n",
    "darker  = adjust_value(img_color, 0.4)\n",
    "lighter = adjust_value(img_color, 1.5)\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "for ax, im, title in zip(axes,\n",
    "                          [darker, img_color, lighter],\n",
    "                          [\"Darker (V×0.4)\", \"Original\", \"Lighter (V×1.5)\"]):\n",
    "    ax.imshow(im)\n",
    "    ax.set_title(title)\n",
    "    ax.axis(\"off\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Practical application: Equalize only the V channel\n",
    "\n",
    "Applying histogram equalization to each RGB channel independently can produce color artifacts. A better approach: convert to HSV, equalize only the Value channel (brightness), and convert back. This preserves the original colors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Equalize only the V channel\n",
    "hsv_eq = rgb_to_hsv(img_color / 255.0)\n",
    "\n",
    "v_uint8 = (hsv_eq[:, :, 2] * 255).astype(np.uint8)\n",
    "hist_v, _ = np.histogram(v_uint8.ravel(), 256, [0, 256])\n",
    "cdf_v = hist_v.cumsum()\n",
    "cdf_v_norm = (cdf_v - cdf_v.min()) * 255 / (cdf_v.max() - cdf_v.min())\n",
    "v_equalized = cdf_v_norm[v_uint8].astype(np.uint8)\n",
    "\n",
    "hsv_eq[:, :, 2] = v_equalized / 255.0\n",
    "result_v_eq = (hsv_to_rgb(hsv_eq) * 255).astype(np.uint8)\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(10, 5))\n",
    "axes[0].imshow(img_color)\n",
    "axes[0].set_title(\"Original\")\n",
    "axes[1].imshow(result_v_eq)\n",
    "axes[1].set_title(\"V-channel equalized\")\n",
    "for ax in axes:\n",
    "    ax.axis(\"off\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercises\n",
    "\n",
    "**Exercise 10.1:** Extract the V channel from the HSV image, convert it to uint8, and compare it with the grayscale image we created earlier using `Image.convert('L')`. Are they identical? Print whether they match and display both side by side. Explain the difference in a comment.\n",
    "\n",
    "*Hint:* `Image.convert('L')` uses the luma formula (weighted sum of R, G, B), while V = max(R, G, B)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 10.2:** Create a 2×3 grid showing the original image and 5 hue-shifted versions (+60°, +120°, +180°, +240°, +300°). Label each with its shift angle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}